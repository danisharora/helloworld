[2016-11-17 15:02:10,069] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:02:10,071] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,072] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,072] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:02:10,073] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,073] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,074] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:02:10,075] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,075] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,076] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:02:10,077] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,077] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,077] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:02:10,079] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,079] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,079] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:02:10,081] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,081] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,081] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:02:10,082] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,082] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,083] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:02:10,084] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,084] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,084] TRACE Controller 0 epoch 58 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:02:10,085] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,086] ERROR Controller 0 epoch 58 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,086] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:02:10,087] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,087] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,087] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:02:10,088] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,089] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,089] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:02:10,090] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,090] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,090] TRACE Controller 0 epoch 58 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:02:10,091] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]. (state.change.logger)
[2016-11-17 15:02:10,091] ERROR Controller 0 epoch 58 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,092] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:02:10,093] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,093] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,093] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:02:10,094] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,094] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,095] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:02:10,096] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,096] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,096] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:02:10,097] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,097] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,098] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:02:10,099] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,099] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,099] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:02:10,100] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,100] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,100] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:02:10,102] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,102] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,102] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:02:10,103] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,103] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,103] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:02:10,104] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,105] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,105] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:02:10,106] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,106] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,106] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:02:10,107] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,107] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,108] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:02:10,109] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,109] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,109] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:02:10,110] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,110] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:02:10,111] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:02:10,112] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:02:10,112] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:09,993] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:07:10,012] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,012] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,013] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:07:10,014] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,014] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,015] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:07:10,016] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,016] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,017] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:07:10,018] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,018] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,018] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:07:10,020] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,020] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,020] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:07:10,022] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,022] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,022] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:07:10,024] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,024] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,024] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:07:10,025] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,025] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,026] TRACE Controller 0 epoch 58 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:07:10,027] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,027] ERROR Controller 0 epoch 58 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,027] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:07:10,029] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,029] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,029] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:07:10,031] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,031] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,031] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:07:10,032] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,032] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,032] TRACE Controller 0 epoch 58 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:07:10,034] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]. (state.change.logger)
[2016-11-17 15:07:10,034] ERROR Controller 0 epoch 58 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,034] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:07:10,035] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,035] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,036] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:07:10,037] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,037] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,037] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:07:10,038] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,038] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,039] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:07:10,040] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,040] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,040] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:07:10,041] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,042] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,042] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:07:10,043] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,043] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,043] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:07:10,045] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,045] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,045] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:07:10,046] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,046] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,046] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:07:10,047] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,048] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,048] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:07:10,049] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,049] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,050] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:07:10,051] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,051] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,051] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:07:10,052] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,052] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,053] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:07:10,054] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,054] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:07:10,054] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:07:10,056] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:07:10,056] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,965] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:12:09,967] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,967] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,967] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:12:09,969] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,969] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,969] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:12:09,971] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,971] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,971] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:12:09,973] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,973] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,973] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:12:09,974] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,974] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,975] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:12:09,976] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,976] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,976] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:12:09,978] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,978] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,978] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:12:09,980] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,980] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,981] TRACE Controller 0 epoch 58 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:12:09,982] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,982] ERROR Controller 0 epoch 58 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,982] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:12:09,983] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,983] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,984] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:12:09,985] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,985] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,985] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:12:09,987] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,987] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,987] TRACE Controller 0 epoch 58 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:12:09,988] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]. (state.change.logger)
[2016-11-17 15:12:09,988] ERROR Controller 0 epoch 58 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,988] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:12:09,990] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,990] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,990] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:12:09,991] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,991] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,991] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:12:09,993] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,993] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,993] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:12:09,994] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,994] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,994] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:12:09,996] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,996] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,996] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:12:09,997] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,997] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,998] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:12:09,999] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:09,999] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:09,999] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:12:10,000] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:10,000] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:10,001] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:12:10,002] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:10,002] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:10,002] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:12:10,003] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:10,003] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:10,004] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:12:10,005] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:10,005] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:10,005] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:12:10,006] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:10,006] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:10,007] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:12:10,008] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:10,008] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:12:10,008] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:12:10,010] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:12:10,010] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,005] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:17:10,014] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,015] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,015] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:17:10,016] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,016] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,017] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:17:10,018] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,018] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,018] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:17:10,019] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,019] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,020] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:17:10,021] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,021] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,021] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:17:10,023] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,023] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,023] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:17:10,025] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,025] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,026] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:17:10,027] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,027] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,027] TRACE Controller 0 epoch 58 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:17:10,028] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,029] ERROR Controller 0 epoch 58 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,029] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:17:10,030] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,030] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,030] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:17:10,031] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,031] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,032] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:17:10,033] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,033] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,033] TRACE Controller 0 epoch 58 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:17:10,034] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]. (state.change.logger)
[2016-11-17 15:17:10,034] ERROR Controller 0 epoch 58 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,035] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:17:10,036] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,036] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,036] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:17:10,037] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,037] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,037] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:17:10,039] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,039] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,039] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:17:10,040] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,040] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,041] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:17:10,042] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,042] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,042] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:17:10,043] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,043] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,044] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:17:10,045] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,045] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,045] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:17:10,046] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,046] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,047] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:17:10,048] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,048] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,048] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:17:10,049] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,049] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,049] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:17:10,050] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,051] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,051] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:17:10,052] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,052] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,052] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:17:10,053] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,053] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:17:10,054] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:17:10,055] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:17:10,055] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,967] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:22:09,981] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,981] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,981] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:22:09,983] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,983] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,983] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:22:09,985] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,985] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,985] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:22:09,987] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,987] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,987] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:22:09,988] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,989] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,989] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:22:09,991] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,991] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,991] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:22:09,993] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,993] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,993] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:22:09,994] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,994] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,995] TRACE Controller 0 epoch 58 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:22:09,996] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,996] ERROR Controller 0 epoch 58 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,996] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:22:09,997] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,997] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,998] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:22:09,999] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:09,999] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:09,999] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:22:10,000] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,000] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,001] TRACE Controller 0 epoch 58 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:22:10,002] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]. (state.change.logger)
[2016-11-17 15:22:10,002] ERROR Controller 0 epoch 58 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,002] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:22:10,004] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,004] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,004] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:22:10,005] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,005] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,006] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:22:10,007] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,007] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,007] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:22:10,008] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,008] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,009] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:22:10,010] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,010] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,010] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:22:10,011] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,011] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,011] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:22:10,012] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,012] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,013] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:22:10,014] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,014] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,014] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:22:10,015] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,015] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,016] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:22:10,017] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,017] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,017] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:22:10,018] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,018] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,019] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:22:10,020] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,020] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,020] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:22:10,021] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,021] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:22:10,021] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:22:10,022] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:22:10,022] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,926] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:27:09,928] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,928] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,928] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:27:09,930] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,930] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,930] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:27:09,932] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,932] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,932] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:27:09,933] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,933] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,934] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:27:09,935] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,935] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,935] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:27:09,936] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,937] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,937] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:27:09,938] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,938] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,938] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:27:09,940] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,940] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,940] TRACE Controller 0 epoch 58 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:27:09,942] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,942] ERROR Controller 0 epoch 58 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,942] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:27:09,944] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,944] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,944] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:27:09,945] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,945] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,946] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:27:09,947] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,947] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,947] TRACE Controller 0 epoch 58 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:27:09,948] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]. (state.change.logger)
[2016-11-17 15:27:09,948] ERROR Controller 0 epoch 58 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,949] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:27:09,950] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,950] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,950] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:27:09,951] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,951] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,951] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:27:09,952] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,952] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,953] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:27:09,954] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,954] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,954] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:27:09,956] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,956] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,956] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:27:09,957] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,957] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,957] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:27:09,959] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,959] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,959] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:27:09,960] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,960] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,961] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:27:09,962] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,962] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,962] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:27:09,963] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,963] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,964] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:27:09,965] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,965] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,965] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:27:09,966] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,966] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,967] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:27:09,968] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,968] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:27:09,968] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:27:09,969] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:27:09,969] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,915] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:32:09,917] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,917] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,917] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:32:09,919] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,919] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,919] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:32:09,920] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,920] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,921] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:32:09,922] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,922] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,922] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:32:09,923] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,923] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,924] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:32:09,925] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,925] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,925] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:32:09,926] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,926] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,927] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:32:09,928] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,928] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,928] TRACE Controller 0 epoch 58 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:32:09,929] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,930] ERROR Controller 0 epoch 58 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,930] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:32:09,931] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,931] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,931] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:32:09,932] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,932] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,933] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:32:09,934] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,934] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,935] TRACE Controller 0 epoch 58 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:32:09,936] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]. (state.change.logger)
[2016-11-17 15:32:09,936] ERROR Controller 0 epoch 58 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,936] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:32:09,937] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,937] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,937] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:32:09,938] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,938] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,939] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:32:09,940] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,940] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,940] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:32:09,941] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,941] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,942] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:32:09,943] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,943] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,943] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:32:09,944] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,944] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,944] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:32:09,945] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,945] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,946] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:32:09,947] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,947] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,947] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:32:09,948] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,948] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,948] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:32:09,949] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,949] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,950] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:32:09,951] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,951] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,951] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:32:09,953] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,953] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,953] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:32:09,954] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,954] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:32:09,954] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:32:09,955] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:32:09,955] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,941] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:37:09,953] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,953] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,954] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:37:09,955] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,955] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,955] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:37:09,956] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,956] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,957] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:37:09,958] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,958] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,958] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:37:09,960] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,960] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,960] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:37:09,961] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,961] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,962] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:37:09,963] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,963] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,963] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:37:09,964] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,964] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,965] TRACE Controller 0 epoch 58 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:37:09,966] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,966] ERROR Controller 0 epoch 58 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,966] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:37:09,967] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,967] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,968] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:37:09,969] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,969] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,969] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:37:09,970] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,970] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,970] TRACE Controller 0 epoch 58 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:37:09,971] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]. (state.change.logger)
[2016-11-17 15:37:09,971] ERROR Controller 0 epoch 58 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [topic2,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":0,"leader_epoch":14,"isr":[0]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,972] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:37:09,973] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,973] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,973] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:37:09,974] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:09,974] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:09,975] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:37:10,002] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,003] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,003] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:37:10,004] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,005] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,005] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:37:10,006] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,006] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,007] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:37:10,008] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,008] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,008] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:37:10,010] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,010] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,010] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:37:10,011] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,011] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,012] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:37:10,013] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,013] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,013] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:37:10,015] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,015] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,015] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:37:10,016] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,016] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,016] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:37:10,018] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,018] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,018] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:37:10,019] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,019] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:37:10,020] TRACE Controller 0 epoch 58 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:37:10,021] ERROR Controller 0 epoch 58 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:37:10,021] ERROR Controller 0 epoch 58 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:15,951] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,28] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,17] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,48] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,5] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,21] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,38] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,39] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,18] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,23] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,48] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,23] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,9] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,42] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,059] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,39] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [topic3,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,31] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [topic2,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,22] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,19] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,10] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,13] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,34] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [othertopic,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,22] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,40] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,33] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,3] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,37] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,24] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,060] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,43] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,40] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,11] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,27] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,6] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,20] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,47] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,30] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,42] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,27] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,41] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,30] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [topic1,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,15] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,3] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,28] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,13] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,061] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,7] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,43] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,10] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,4] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,16] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,46] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,12] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,32] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,49] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [topic4,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,14] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,4] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,26] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,35] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,45] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,46] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,37] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,29] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [othertopic,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,20] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,8] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,6] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,38] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,062] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [othertopic,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,8] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,44] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,7] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,45] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [topic2,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [topic2,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [topic2,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [topic3,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,49] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,19] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,34] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,36] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,33] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,14] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,26] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,44] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [othertopic,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,32] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,063] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,25] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,11] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,31] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,21] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [othertopic,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,25] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,5] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,41] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,47] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,36] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [othertopic,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,12] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,16] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [topic2,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,35] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,29] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,064] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,15] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,18] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,17] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [__consumer_offsets,24] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 changed state of replica 1 for partition [topic2,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 changed state of replica 2 for partition [__consumer_offsets,9] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 2 for partition [othertopic,1] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:38) to broker 2 for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 2 for partition [topic1,0] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 15:46:16,065] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 2 for partition [topic2,1] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 2 for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 15:46:16,066] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 2 for partition [topic3,2] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:48,ControllerEpoch:38) to broker 2 for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:14,ControllerEpoch:58) to broker 2 for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 15:46:16,067] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition [othertopic,1] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 1 for partition [topic3,1] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:38) to broker 1 for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:38) to broker 1 for partition [topic4,0] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:46:16,068] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition [topic2,1] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 1 for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:46:16,069] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:48,ControllerEpoch:38) to broker 1 for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:14,ControllerEpoch:58) to broker 1 for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 15:46:16,071] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 2 for partition topic3-1 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:38) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 2 for partition topic1-0 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:38) to broker 2 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:16,072] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 2 for partition topic3-2 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:48,ControllerEpoch:38) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:14,ControllerEpoch:58) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:16,073] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 1 for partition topic3-1 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:6,ControllerEpoch:38) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 1 for partition topic1-0 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:3,ControllerEpoch:38) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 15:46:16,074] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:16,075] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:16,079] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 1 for partition topic3-2 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:48,ControllerEpoch:38) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:14,ControllerEpoch:58) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:16,080] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 15:46:16,173] TRACE Controller 0 epoch 59 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:16,180] TRACE Controller 0 epoch 59 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=19,error_code=13},{topic=__consumer_offsets,partition=30,error_code=13},{topic=__consumer_offsets,partition=47,error_code=13},{topic=__consumer_offsets,partition=29,error_code=13},{topic=__consumer_offsets,partition=41,error_code=13},{topic=topic2,partition=1,error_code=13},{topic=__consumer_offsets,partition=39,error_code=13},{topic=__consumer_offsets,partition=17,error_code=13},{topic=__consumer_offsets,partition=10,error_code=13},{topic=__consumer_offsets,partition=14,error_code=13},{topic=topic3,partition=1,error_code=13},{topic=__consumer_offsets,partition=40,error_code=13},{topic=__consumer_offsets,partition=18,error_code=13},{topic=__consumer_offsets,partition=26,error_code=13},{topic=__consumer_offsets,partition=0,error_code=13},{topic=__consumer_offsets,partition=24,error_code=13},{topic=__consumer_offsets,partition=33,error_code=13},{topic=othertopic,partition=0,error_code=13},{topic=__consumer_offsets,partition=20,error_code=13},{topic=__consumer_offsets,partition=3,error_code=13},{topic=__consumer_offsets,partition=21,error_code=13},{topic=__consumer_offsets,partition=5,error_code=13},{topic=__consumer_offsets,partition=22,error_code=13},{topic=othertopic,partition=1,error_code=13},{topic=__consumer_offsets,partition=12,error_code=13},{topic=topic2,partition=0,error_code=13},{topic=__consumer_offsets,partition=8,error_code=13},{topic=__consumer_offsets,partition=23,error_code=13},{topic=__consumer_offsets,partition=15,error_code=13},{topic=__consumer_offsets,partition=11,error_code=13},{topic=__consumer_offsets,partition=48,error_code=13},{topic=__consumer_offsets,partition=13,error_code=13},{topic=__consumer_offsets,partition=49,error_code=13},{topic=__consumer_offsets,partition=6,error_code=13},{topic=__consumer_offsets,partition=28,error_code=13},{topic=__consumer_offsets,partition=4,error_code=13},{topic=__consumer_offsets,partition=37,error_code=13},{topic=__consumer_offsets,partition=31,error_code=13},{topic=__consumer_offsets,partition=44,error_code=13},{topic=__consumer_offsets,partition=42,error_code=13},{topic=__consumer_offsets,partition=34,error_code=13},{topic=__consumer_offsets,partition=46,error_code=13},{topic=__consumer_offsets,partition=25,error_code=13},{topic=__consumer_offsets,partition=45,error_code=13},{topic=__consumer_offsets,partition=27,error_code=13},{topic=__consumer_offsets,partition=32,error_code=13},{topic=topic2,partition=2,error_code=13},{topic=__consumer_offsets,partition=43,error_code=13},{topic=othertopic,partition=2,error_code=13},{topic=__consumer_offsets,partition=36,error_code=13},{topic=__consumer_offsets,partition=35,error_code=13},{topic=__consumer_offsets,partition=7,error_code=13},{topic=__consumer_offsets,partition=38,error_code=13},{topic=__consumer_offsets,partition=9,error_code=13},{topic=__consumer_offsets,partition=1,error_code=13},{topic=topic4,partition=0,error_code=13},{topic=__consumer_offsets,partition=16,error_code=13},{topic=__consumer_offsets,partition=2,error_code=13}]} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:16,185] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:16,478] TRACE Controller 0 epoch 59 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=19,error_code=13},{topic=__consumer_offsets,partition=30,error_code=13},{topic=__consumer_offsets,partition=47,error_code=13},{topic=__consumer_offsets,partition=29,error_code=13},{topic=__consumer_offsets,partition=41,error_code=13},{topic=topic2,partition=1,error_code=13},{topic=__consumer_offsets,partition=39,error_code=13},{topic=__consumer_offsets,partition=17,error_code=13},{topic=__consumer_offsets,partition=10,error_code=13},{topic=__consumer_offsets,partition=14,error_code=13},{topic=__consumer_offsets,partition=40,error_code=13},{topic=__consumer_offsets,partition=18,error_code=13},{topic=__consumer_offsets,partition=26,error_code=13},{topic=__consumer_offsets,partition=0,error_code=13},{topic=__consumer_offsets,partition=24,error_code=13},{topic=__consumer_offsets,partition=33,error_code=13},{topic=othertopic,partition=0,error_code=13},{topic=__consumer_offsets,partition=20,error_code=13},{topic=__consumer_offsets,partition=3,error_code=13},{topic=__consumer_offsets,partition=21,error_code=13},{topic=__consumer_offsets,partition=5,error_code=13},{topic=__consumer_offsets,partition=22,error_code=13},{topic=othertopic,partition=1,error_code=13},{topic=__consumer_offsets,partition=12,error_code=13},{topic=topic2,partition=0,error_code=13},{topic=__consumer_offsets,partition=8,error_code=13},{topic=__consumer_offsets,partition=23,error_code=13},{topic=__consumer_offsets,partition=15,error_code=13},{topic=__consumer_offsets,partition=11,error_code=13},{topic=__consumer_offsets,partition=48,error_code=13},{topic=__consumer_offsets,partition=13,error_code=13},{topic=__consumer_offsets,partition=49,error_code=13},{topic=__consumer_offsets,partition=6,error_code=13},{topic=__consumer_offsets,partition=28,error_code=13},{topic=__consumer_offsets,partition=4,error_code=13},{topic=__consumer_offsets,partition=37,error_code=13},{topic=__consumer_offsets,partition=31,error_code=13},{topic=__consumer_offsets,partition=44,error_code=13},{topic=__consumer_offsets,partition=42,error_code=13},{topic=__consumer_offsets,partition=34,error_code=13},{topic=topic1,partition=0,error_code=13},{topic=__consumer_offsets,partition=46,error_code=13},{topic=topic3,partition=2,error_code=13},{topic=__consumer_offsets,partition=25,error_code=13},{topic=__consumer_offsets,partition=45,error_code=13},{topic=__consumer_offsets,partition=27,error_code=13},{topic=__consumer_offsets,partition=32,error_code=13},{topic=topic2,partition=2,error_code=13},{topic=__consumer_offsets,partition=43,error_code=13},{topic=othertopic,partition=2,error_code=13},{topic=__consumer_offsets,partition=36,error_code=13},{topic=__consumer_offsets,partition=35,error_code=13},{topic=__consumer_offsets,partition=7,error_code=13},{topic=__consumer_offsets,partition=38,error_code=13},{topic=__consumer_offsets,partition=9,error_code=13},{topic=__consumer_offsets,partition=1,error_code=13},{topic=__consumer_offsets,partition=16,error_code=13},{topic=__consumer_offsets,partition=2,error_code=13}]} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:16,547] TRACE Controller 0 epoch 59 elected leader 1 for Offline partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:16,548] TRACE Controller 0 epoch 59 changed partition [topic2,0] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 15:46:16,548] TRACE Controller 0 epoch 59 started leader election for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:16,551] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:16,632] TRACE Controller 0 epoch 59 elected leader 2 for Offline partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:16,633] TRACE Controller 0 epoch 59 changed partition [topic2,2] from OfflinePartition to OnlinePartition with leader 2 (state.change.logger)
[2016-11-17 15:46:16,633] TRACE Controller 0 epoch 59 started leader election for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:16,731] TRACE Controller 0 epoch 59 elected leader 1 for Offline partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:16,732] TRACE Controller 0 epoch 59 changed partition [othertopic,2] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 15:46:16,732] TRACE Controller 0 epoch 59 started leader election for partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:16,735] ERROR Controller 0 epoch 59 initiated state change for partition [mytopic,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [mytopic,0] is alive. Live brokers are: [Set(1, 2)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-11-17 15:46:16,735] TRACE Controller 0 epoch 59 started leader election for partition [topic4,0] (state.change.logger)
[2016-11-17 15:46:16,945] TRACE Controller 0 epoch 59 elected leader 1 for Offline partition [topic4,0] (state.change.logger)
[2016-11-17 15:46:17,001] TRACE Controller 0 epoch 59 changed partition [topic4,0] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 15:46:17,001] TRACE Controller 0 epoch 59 started leader election for partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:17,004] ERROR Controller 0 epoch 59 initiated state change for partition [topic3,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [topic3,0] is alive. Live brokers are: [Set(1, 2)], Assigned replicas are: [List(0)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-11-17 15:46:17,040] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 2 for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:17,040] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:17,040] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 1 for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition [topic4,0] (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 2 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:17,041] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:17,103] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 2 for partition topic3-1 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 2 for partition topic1-0 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 2 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 2 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:17,275] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 2 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 15:46:17,360] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:17,391] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:17,391] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:17,391] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 15:46:17,391] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:17,391] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 15:46:17,391] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 15:46:17,391] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:17,391] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 2 for partition topic3-2 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 1 for partition topic3-1 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:17,392] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 1 for partition topic1-0 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 1 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 1 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 1 for partition topic3-2 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:17,393] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:17,394] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 15:46:17,394] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:17,394] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:17,394] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 15:46:17,394] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:17,394] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 15:46:17,394] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:17,427] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 15:46:17,427] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:17,427] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:17,427] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 15:46:17,429] TRACE Controller 0 epoch 59 received response {error_code=0,partitions=[{topic=topic2,partition=0,error_code=-1},{topic=othertopic,partition=2,error_code=-1},{topic=topic2,partition=2,error_code=-1},{topic=topic4,partition=0,error_code=-1}]} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:17,431] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:17,787] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:22,445] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:46:22,446] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,447] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,447] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:46:22,449] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,449] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,450] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:46:22,451] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,451] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,452] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:46:22,454] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,454] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,455] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:46:22,457] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,457] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,457] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:46:22,459] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,459] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,460] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:46:22,461] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,461] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,462] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:46:22,463] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,463] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,463] TRACE Controller 0 epoch 59 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:46:22,465] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,465] ERROR Controller 0 epoch 59 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,465] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:46:22,467] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,467] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,467] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:46:22,469] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,469] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,469] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:46:22,470] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,471] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,471] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:46:22,472] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,472] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,473] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:46:22,474] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,474] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,474] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:46:22,476] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,476] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,476] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:46:22,478] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,478] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,479] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:46:22,480] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,480] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,481] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:46:22,482] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,482] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,483] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:46:22,485] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,485] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,485] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:46:22,487] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,487] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,487] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:46:22,488] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,489] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,489] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:46:22,490] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,490] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,491] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:46:22,492] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,492] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,492] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:46:22,494] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,494] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,494] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:46:22,495] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,495] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,496] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:46:22,497] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:46:22,497] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 2 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:22,911] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:22,912] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:22,936] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 2 for partition topic3-1 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 2 for partition topic1-0 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 2 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 2 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 2 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 2 for partition topic3-2 (state.change.logger)
[2016-11-17 15:46:22,946] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 2 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 1 for partition topic3-1 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 1 for partition topic1-0 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 1 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 1 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 15:46:22,947] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 1 for partition topic3-2 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 0 for partition topic3-1 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 0 for partition topic1-0 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 0 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 0 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 0 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:22,948] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 0 for partition topic3-2 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [othertopic,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [mytopic,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [othertopic,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [topic2,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,949] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [topic2,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [topic2,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [topic3,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [othertopic,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 changed state of replica 0 for partition [topic4,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 0 for partition [othertopic,1] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 0 for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 0 for partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 0 for partition [topic4,0] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 0 for partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 0 for partition [topic2,1] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 0 for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 2 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 2 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 2 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 1 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 1 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38) to broker 0 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 0 for partition topic4-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38) to broker 0 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:22,950] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Controller 0 epoch 59 started leader election for partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,32] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,16] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,2,1) for partition [topic2,2] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,49] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,44] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,28] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53),ReplicationFactor:3),AllReplicas:2,1,0) for partition [topic2,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,17] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,23] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,7] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,4] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,29] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59),ReplicationFactor:2),AllReplicas:0,1) for partition [topic4,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,35] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,3] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,24] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,41] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,951] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52),ReplicationFactor:1),AllReplicas:2) for partition [topic1,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,38] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,13] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,8] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,5] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,39] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,36] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58),ReplicationFactor:1),AllReplicas:1) for partition [topic3,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,40] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,1,2) for partition [othertopic,2] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,45] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,15] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,33] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,37] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,21] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,6] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,11] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,20] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,47] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,2] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,27] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52),ReplicationFactor:1),AllReplicas:2) for partition [topic3,2] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38),ReplicationFactor:1),AllReplicas:0) for partition [mytopic,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,34] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,9] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,22] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,42] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,14] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,25] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,10] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:1,0,2) for partition [topic2,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,952] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,48] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,31] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,18] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,19] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,12] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38),ReplicationFactor:1),AllReplicas:0) for partition [topic3,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,46] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,43] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:36,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,26] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,30] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58),ReplicationFactor:3),AllReplicas:1,2,0) for partition [othertopic,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 0 (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Controller 0 epoch 59 elected leader 0 for Offline partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 15:46:22,953] TRACE Controller 0 epoch 59 changed partition [mytopic,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Controller 0 epoch 59 started leader election for partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,2,1) correlation id 1 from controller 0 epoch 59 for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53),ReplicationFactor:3),AllReplicas:2,1,0) correlation id 1 from controller 0 epoch 59 for partition [topic2,1] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59),ReplicationFactor:2),AllReplicas:0,1) correlation id 1 from controller 0 epoch 59 for partition [topic4,0] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,1,2) correlation id 1 from controller 0 epoch 59 for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53),ReplicationFactor:3),AllReplicas:2,0,1) correlation id 1 from controller 0 epoch 59 for partition [othertopic,1] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38),ReplicationFactor:1),AllReplicas:0) correlation id 1 from controller 0 epoch 59 for partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:1,0,2) correlation id 1 from controller 0 epoch 59 for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38),ReplicationFactor:1),AllReplicas:0) correlation id 1 from controller 0 epoch 59 for partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:22,954] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58),ReplicationFactor:3),AllReplicas:1,2,0) correlation id 1 from controller 0 epoch 59 for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:46:22,954] WARN Broker 0 ignoring LeaderAndIsr request from controller 0 with correlation id 1 epoch 59 for partition [topic2,1] since its associated leader epoch 17 is old. Current leader epoch is 17 (state.change.logger)
[2016-11-17 15:46:22,954] WARN Broker 0 ignoring LeaderAndIsr request from controller 0 with correlation id 1 epoch 59 for partition [othertopic,1] since its associated leader epoch 53 is old. Current leader epoch is 53 (state.change.logger)
[2016-11-17 15:46:22,954] WARN Broker 0 ignoring LeaderAndIsr request from controller 0 with correlation id 1 epoch 59 for partition [mytopic,0] since its associated leader epoch 37 is old. Current leader epoch is 37 (state.change.logger)
[2016-11-17 15:46:22,954] WARN Broker 0 ignoring LeaderAndIsr request from controller 0 with correlation id 1 epoch 59 for partition [topic3,0] since its associated leader epoch 4 is old. Current leader epoch is 4 (state.change.logger)
[2016-11-17 15:46:22,954] WARN Broker 0 ignoring LeaderAndIsr request from controller 0 with correlation id 1 epoch 59 for partition [othertopic,0] since its associated leader epoch 49 is old. Current leader epoch is 49 (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 59 starting the become-follower transition for partition [topic4,0] (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 59 starting the become-follower transition for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 59 starting the become-follower transition for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Broker 0 handling LeaderAndIsr request correlationId 1 from controller 0 epoch 59 starting the become-follower transition for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 0 epoch 59 with correlation id 1 for partition [topic2,0] (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 0 epoch 59 with correlation id 1 for partition [topic2,2] (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 0 epoch 59 with correlation id 1 for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Broker 0 stopped fetchers as part of become-follower request from controller 0 epoch 59 with correlation id 1 for partition [topic4,0] (state.change.logger)
[2016-11-17 15:46:22,955] TRACE Controller 0 epoch 59 elected leader 0 for Offline partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 changed partition [topic3,0] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 0 for partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 0 for partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 2 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 2 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 1 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 1 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 0 for partition mytopic-0 (state.change.logger)
[2016-11-17 15:46:22,956] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 0 for partition topic3-0 (state.change.logger)
[2016-11-17 15:46:22,957] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [topic2,0] as part of become-follower request with correlation id 1 from controller 0 epoch 59 (state.change.logger)
[2016-11-17 15:46:22,957] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [topic2,2] as part of become-follower request with correlation id 1 from controller 0 epoch 59 (state.change.logger)
[2016-11-17 15:46:22,957] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [othertopic,2] as part of become-follower request with correlation id 1 from controller 0 epoch 59 (state.change.logger)
[2016-11-17 15:46:22,957] TRACE Broker 0 truncated logs and checkpointed recovery boundaries for partition [topic4,0] as part of become-follower request with correlation id 1 from controller 0 epoch 59 (state.change.logger)
[2016-11-17 15:46:22,957] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:22,959] ERROR Error on broker 0 while processing LeaderAndIsr request with correlationId 1 received from controller 0 epoch 59 (state.change.logger)
java.lang.IllegalArgumentException: A metric named 'MetricName [name=connection-close-rate, group=replica-fetcher-metrics, description=Connections closed per second in the window., tags={broker-id=1, fetcher-id=0}]' already exists, can't register another one.
	at org.apache.kafka.common.metrics.Metrics.registerMetric(Metrics.java:285)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:177)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:162)
	at org.apache.kafka.common.network.Selector$SelectorMetrics.<init>(Selector.java:572)
	at org.apache.kafka.common.network.Selector.<init>(Selector.java:112)
	at kafka.server.ReplicaFetcherThread.<init>(ReplicaFetcherThread.scala:73)
	at kafka.server.ReplicaFetcherManager.createFetcherThread(ReplicaFetcherManager.scala:35)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:83)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:78)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.server.AbstractFetcherManager.addFetcherForPartitions(AbstractFetcherManager.scala:78)
	at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:816)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:641)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:131)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:72)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-17 15:46:22,960] TRACE Controller 0 epoch 59 received response {error_code=0,partitions=[{topic=topic2,partition=2,error_code=-1},{topic=topic2,partition=1,error_code=-1},{topic=topic4,partition=0,error_code=-1},{topic=othertopic,partition=2,error_code=-1},{topic=othertopic,partition=1,error_code=-1},{topic=mytopic,partition=0,error_code=-1},{topic=topic2,partition=0,error_code=-1},{topic=topic3,partition=0,error_code=-1},{topic=othertopic,partition=0,error_code=-1}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 15:46:22,960] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,2,1) for partition [topic2,2] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:17,ControllerEpoch:53),ReplicationFactor:3),AllReplicas:2,1,0) for partition [topic2,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59),ReplicationFactor:2),AllReplicas:0,1) for partition [topic4,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,1,2) for partition [othertopic,2] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:37,ControllerEpoch:38),ReplicationFactor:1),AllReplicas:0) for partition [mytopic,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:1,0,2) for partition [topic2,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:4,ControllerEpoch:38),ReplicationFactor:1),AllReplicas:0) for partition [topic3,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58),ReplicationFactor:3),AllReplicas:1,2,0) for partition [othertopic,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 2 (state.change.logger)
[2016-11-17 15:46:22,961] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 15:46:22,962] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59),ReplicationFactor:1),AllReplicas:0) correlation id 3 from controller 0 epoch 59 for partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:22,962] TRACE Broker 0 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59),ReplicationFactor:1),AllReplicas:0) correlation id 3 from controller 0 epoch 59 for partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:22,962] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 59 starting the become-leader transition for partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:22,962] TRACE Broker 0 handling LeaderAndIsr request correlationId 3 from controller 0 epoch 59 starting the become-leader transition for partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:22,962] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 59 for partition [mytopic,0] since it is already the leader for the partition. (state.change.logger)
[2016-11-17 15:46:22,962] INFO Broker 0 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 0 epoch 59 for partition [topic3,0] since it is already the leader for the partition. (state.change.logger)
[2016-11-17 15:46:22,962] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 59 for the become-leader transition for partition [mytopic,0] (state.change.logger)
[2016-11-17 15:46:22,962] TRACE Broker 0 completed LeaderAndIsr request correlationId 3 from controller 0 epoch 59 for the become-leader transition for partition [topic3,0] (state.change.logger)
[2016-11-17 15:46:22,965] TRACE Controller 0 epoch 59 received response {error_code=0,partitions=[{topic=mytopic,partition=0,error_code=0},{topic=topic3,partition=0,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 15:46:22,966] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59),ReplicationFactor:1),AllReplicas:0) for partition [mytopic,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 4 (state.change.logger)
[2016-11-17 15:46:22,966] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59),ReplicationFactor:1),AllReplicas:0) for partition [topic3,0] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 4 (state.change.logger)
[2016-11-17 15:46:22,966] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 15:46:34,467] TRACE Controller 0 epoch 59 received response {error_code=0,partitions=[{topic=topic2,partition=0,error_code=0},{topic=othertopic,partition=2,error_code=0},{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:34,468] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:34,470] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:34,471] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:34,474] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:34,475] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:34,475] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:53,ControllerEpoch:53) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:17,ControllerEpoch:53) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:43,334] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:53,ControllerEpoch:53) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:17,ControllerEpoch:53) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 15:46:43,335] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 15:46:43,336] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 15:46:43,336] TRACE Controller 0 epoch 59 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(2, localhost, 9094) (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,49] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:17,ControllerEpoch:53),ReplicationFactor:3),AllReplicas:2,1,0) for partition [topic2,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,17] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,23] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,7] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,29] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,35] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(1, localhost, 9093) (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,3] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,41] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,13] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,337] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,5] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,39] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,45] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,15] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,33] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,37] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,21] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,0,1,LeaderEpoch:53,ControllerEpoch:53),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,11] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,47] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,27] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,9] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,25] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,31] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,19] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,43] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Broker 0 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,1] in response to UpdateMetadata request sent by controller 0 epoch 59 with correlation id 5 (state.change.logger)
[2016-11-17 15:46:43,338] TRACE Controller 0 epoch 59 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 15:51:22,431] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:51:22,442] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,442] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,442] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:51:22,443] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,443] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,444] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:51:22,446] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,446] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,446] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:51:22,447] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,447] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,448] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:51:22,449] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,449] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,449] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:51:22,450] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,450] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,451] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:51:22,452] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,452] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,452] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:51:22,453] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,453] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,454] TRACE Controller 0 epoch 59 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:51:22,455] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,455] ERROR Controller 0 epoch 59 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,455] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:51:22,456] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,456] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,456] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:51:22,457] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,457] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,458] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:51:22,459] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,459] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,459] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:51:22,460] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,460] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,461] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:51:22,462] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,462] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,462] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:51:22,463] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,463] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,464] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:51:22,465] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,465] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,465] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:51:22,466] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,466] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,467] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:51:22,468] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,468] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,468] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:51:22,469] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,470] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,470] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:51:22,471] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,471] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,472] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:51:22,473] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,473] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,474] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:51:22,475] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,475] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,476] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:51:22,477] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,477] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,477] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:51:22,478] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,478] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,479] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:51:22,480] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,480] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,480] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:51:22,481] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,481] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,482] TRACE Controller 0 epoch 59 started leader election for partition [topic2,2] (state.change.logger)
[2016-11-17 15:51:22,483] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [topic2,2] due to: Preferred replica 0 for partition [topic2,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":7,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:51:22,483] ERROR Controller 0 epoch 59 initiated state change for partition [topic2,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,2] due to: Preferred replica 0 for partition [topic2,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":7,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [topic2,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":7,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,483] TRACE Controller 0 epoch 59 started leader election for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:51:22,484] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [othertopic,2] due to: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}]. (state.change.logger)
[2016-11-17 15:51:22,484] ERROR Controller 0 epoch 59 initiated state change for partition [othertopic,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,2] due to: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:51:22,485] TRACE Controller 0 epoch 59 started leader election for partition [topic4,0] (state.change.logger)
[2016-11-17 15:51:22,486] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [topic4,0] due to: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}]. (state.change.logger)
[2016-11-17 15:51:22,486] ERROR Controller 0 epoch 59 initiated state change for partition [topic4,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic4,0] due to: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,425] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 15:56:22,445] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,445] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,30] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,446] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 15:56:22,447] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,447] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,10] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,447] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 15:56:22,448] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,448] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,14] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,449] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 15:56:22,450] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,450] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,40] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,450] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 15:56:22,452] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,452] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,18] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,452] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 15:56:22,454] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,454] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,454] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 15:56:22,455] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,456] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,26] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,456] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 15:56:22,457] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,457] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,24] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,458] TRACE Controller 0 epoch 59 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 15:56:22,460] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,461] ERROR Controller 0 epoch 59 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [othertopic,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":49,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,461] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 15:56:22,463] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,463] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,20] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,463] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 15:56:22,465] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,465] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,22] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,466] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 15:56:22,467] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,467] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,12] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,467] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 15:56:22,469] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,469] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,8] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,469] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 15:56:22,471] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,471] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,48] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,471] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 15:56:22,472] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,472] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,6] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,473] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 15:56:22,474] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,475] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,28] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,475] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 15:56:22,478] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,478] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,4] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,479] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 15:56:22,481] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,481] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,44] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,481] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 15:56:22,483] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,484] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,42] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,484] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 15:56:22,486] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,486] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,34] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,487] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 15:56:22,489] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,489] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,46] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,489] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 15:56:22,492] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,492] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,32] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":33,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,493] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 15:56:22,495] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,495] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,36] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,496] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 15:56:22,498] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,498] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,38] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,499] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 15:56:22,501] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,501] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":34,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,501] TRACE Controller 0 epoch 59 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 15:56:22,503] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,503] ERROR Controller 0 epoch 59 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 1 for partition [__consumer_offsets,16] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":35,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,504] TRACE Controller 0 epoch 59 started leader election for partition [topic2,2] (state.change.logger)
[2016-11-17 15:56:22,506] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [topic2,2] due to: Preferred replica 0 for partition [topic2,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":7,"isr":[2]}]. (state.change.logger)
[2016-11-17 15:56:22,506] ERROR Controller 0 epoch 59 initiated state change for partition [topic2,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,2] due to: Preferred replica 0 for partition [topic2,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":7,"isr":[2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [topic2,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":2,"leader_epoch":7,"isr":[2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,508] TRACE Controller 0 epoch 59 started leader election for partition [othertopic,2] (state.change.logger)
[2016-11-17 15:56:22,510] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [othertopic,2] due to: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}]. (state.change.logger)
[2016-11-17 15:56:22,510] ERROR Controller 0 epoch 59 initiated state change for partition [othertopic,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,2] due to: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 15:56:22,510] TRACE Controller 0 epoch 59 started leader election for partition [topic4,0] (state.change.logger)
[2016-11-17 15:56:22,513] ERROR Controller 0 epoch 59 encountered error while electing leader for partition [topic4,0] due to: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}]. (state.change.logger)
[2016-11-17 15:56:22,513] ERROR Controller 0 epoch 59 initiated state change for partition [topic4,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic4,0] due to: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
