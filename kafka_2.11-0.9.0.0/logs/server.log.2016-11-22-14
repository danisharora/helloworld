[2016-11-22 15:02:02,658] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [test1,1] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:02:02,715] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [test1,0] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:02:02,719] INFO Truncating log test1-0 to offset 0. (kafka.log.Log)
[2016-11-22 15:02:02,730] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[test1,0], initOffset 0 to broker BrokerEndPoint(1,172.16.26.72,9010)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:02:02,779] INFO [ReplicaFetcherThread-0-1], Starting  (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:08:39,182] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:18:39,157] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:28:39,135] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:38:39,115] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:50:03,214] WARN [ReplicaFetcherThread-0-0], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@7bd920d6. Possible cause: java.io.IOException: Connection to 0 was disconnected before the response was read (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:50:03,216] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@2b21de7e. Possible cause: java.io.IOException: Connection to 1 was disconnected before the response was read (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:50:03,236] INFO Partition [test1,1] on broker 2: Shrinking ISR for partition [test1,1] from 0,1,2 to 2 (kafka.cluster.Partition)
[2016-11-22 15:50:05,852] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-11-22 15:50:06,159] INFO Result of znode creation is: NODEEXISTS (kafka.utils.ZKCheckedEphemeral)
[2016-11-22 15:50:06,185] INFO re-registering broker info in ZK for broker 2 (kafka.server.KafkaHealthcheck)
[2016-11-22 15:50:06,194] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
[2016-11-22 15:50:06,438] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
[2016-11-22 15:50:06,439] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT -> EndPoint(localhost,9011,PLAINTEXT) (kafka.utils.ZkUtils)
[2016-11-22 15:50:06,440] INFO done re-registering broker (kafka.server.KafkaHealthcheck)
[2016-11-22 15:50:06,442] INFO Subscribing to /brokers/topics path to watch for new topics (kafka.server.KafkaHealthcheck)
[2016-11-22 15:50:06,451] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-11-22 15:50:08,299] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [test1,2] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:50:08,300] INFO Truncating log test1-2 to offset 0. (kafka.log.Log)
[2016-11-22 15:50:08,325] ERROR [KafkaApi-2] error when handling request Name:LeaderAndIsrRequest;Version:0;Controller:0;ControllerEpoch:35;CorrelationId:2;ClientId:0;Leaders:BrokerEndPoint(1,localhost,9010);PartitionState:(test1,2) -> (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:0,1,2) (kafka.server.KafkaApis)
java.lang.IllegalArgumentException: A metric named 'MetricName [name=connection-close-rate, group=replica-fetcher-metrics, description=Connections closed per second in the window., tags={broker-id=1, fetcher-id=0}]' already exists, can't register another one.
	at org.apache.kafka.common.metrics.Metrics.registerMetric(Metrics.java:285)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:177)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:162)
	at org.apache.kafka.common.network.Selector$SelectorMetrics.<init>(Selector.java:572)
	at org.apache.kafka.common.network.Selector.<init>(Selector.java:112)
	at kafka.server.ReplicaFetcherThread.<init>(ReplicaFetcherThread.scala:73)
	at kafka.server.ReplicaFetcherManager.createFetcherThread(ReplicaFetcherManager.scala:35)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:83)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:78)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.server.AbstractFetcherManager.addFetcherForPartitions(AbstractFetcherManager.scala:78)
	at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:816)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:641)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:131)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:72)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-22 15:50:35,233] WARN [ReplicaFetcherThread-0-0], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@5f06ea67. Possible cause: java.io.IOException: Connection to Node(0, 172.16.26.72, 9009) failed (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:50:35,244] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@562b75c7. Possible cause: java.io.IOException: Connection to Node(1, 172.16.26.72, 9010) failed (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:50:37,257] INFO Partition [test1,1] on broker 2: Expanding ISR for partition [test1,1] from 2 to 2,1 (kafka.cluster.Partition)
[2016-11-22 15:50:37,273] INFO Partition [test1,1] on broker 2: Expanding ISR for partition [test1,1] from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2016-11-22 15:57:01,598] INFO [Group Metadata Manager on Broker 2]: Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:55,856] INFO Completed load of log topic66-1 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:55,858] INFO Created log for partition [topic66,1] in /tmp/kafka-logs-2 with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:55,860] INFO Partition [topic66,1] on broker 2: No checkpointed highwatermark is found for partition [topic66,1] (kafka.cluster.Partition)
[2016-11-22 15:57:55,861] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [topic66,1] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:55,861] INFO Truncating log topic66-1 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:55,866] ERROR [KafkaApi-2] error when handling request Name:LeaderAndIsrRequest;Version:0;Controller:0;ControllerEpoch:35;CorrelationId:15;ClientId:0;Leaders:BrokerEndPoint(1,localhost,9010);PartitionState:(topic66,1) -> (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:18,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:2,1,0) (kafka.server.KafkaApis)
java.lang.IllegalArgumentException: A metric named 'MetricName [name=connection-close-rate, group=replica-fetcher-metrics, description=Connections closed per second in the window., tags={broker-id=1, fetcher-id=0}]' already exists, can't register another one.
	at org.apache.kafka.common.metrics.Metrics.registerMetric(Metrics.java:285)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:177)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:162)
	at org.apache.kafka.common.network.Selector$SelectorMetrics.<init>(Selector.java:572)
	at org.apache.kafka.common.network.Selector.<init>(Selector.java:112)
	at kafka.server.ReplicaFetcherThread.<init>(ReplicaFetcherThread.scala:73)
	at kafka.server.ReplicaFetcherManager.createFetcherThread(ReplicaFetcherManager.scala:35)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:83)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:78)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.server.AbstractFetcherManager.addFetcherForPartitions(AbstractFetcherManager.scala:78)
	at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:816)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:641)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:131)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:72)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-22 15:57:55,876] INFO [ReplicaFetcherThread-0-0], Shutting down (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:57:55,881] INFO [ReplicaFetcherThread-0-0], Stopped  (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:57:55,881] INFO [ReplicaFetcherThread-0-0], Shutdown completed (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:57:56,207] INFO Completed load of log topic44-1 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:56,208] INFO Created log for partition [topic44,1] in /tmp/kafka-logs-2 with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:56,209] INFO Partition [topic44,1] on broker 2: No checkpointed highwatermark is found for partition [topic44,1] (kafka.cluster.Partition)
[2016-11-22 15:57:56,209] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [topic44,1] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,209] INFO Truncating log topic44-1 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:56,213] ERROR [KafkaApi-2] error when handling request Name:LeaderAndIsrRequest;Version:0;Controller:0;ControllerEpoch:35;CorrelationId:24;ClientId:0;Leaders:BrokerEndPoint(1,localhost,9010);PartitionState:(topic44,1) -> (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:25,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:0,2,1) (kafka.server.KafkaApis)
java.lang.IllegalArgumentException: A metric named 'MetricName [name=connection-close-rate, group=replica-fetcher-metrics, description=Connections closed per second in the window., tags={broker-id=1, fetcher-id=0}]' already exists, can't register another one.
	at org.apache.kafka.common.metrics.Metrics.registerMetric(Metrics.java:285)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:177)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:162)
	at org.apache.kafka.common.network.Selector$SelectorMetrics.<init>(Selector.java:572)
	at org.apache.kafka.common.network.Selector.<init>(Selector.java:112)
	at kafka.server.ReplicaFetcherThread.<init>(ReplicaFetcherThread.scala:73)
	at kafka.server.ReplicaFetcherManager.createFetcherThread(ReplicaFetcherManager.scala:35)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:83)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:78)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.server.AbstractFetcherManager.addFetcherForPartitions(AbstractFetcherManager.scala:78)
	at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:816)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:641)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:131)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:72)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-22 15:57:56,288] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:56,289] INFO Created log for partition [__consumer_offsets,3] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:56,290] INFO Partition [__consumer_offsets,3] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2016-11-22 15:57:56,290] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,3] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,290] INFO Truncating log __consumer_offsets-3 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:56,295] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,3], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,300] INFO [ReplicaFetcherThread-0-0], Starting  (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:57:56,336] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:56,337] INFO Created log for partition [__consumer_offsets,24] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:56,337] INFO Partition [__consumer_offsets,24] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2016-11-22 15:57:56,338] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,24] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,338] INFO Truncating log __consumer_offsets-24 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:56,340] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,24], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,595] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:56,596] INFO Created log for partition [__consumer_offsets,0] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:56,598] INFO Partition [__consumer_offsets,0] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2016-11-22 15:57:56,598] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,599] INFO Truncating log __consumer_offsets-0 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:56,601] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,0], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,827] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:56,829] INFO Created log for partition [__consumer_offsets,39] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:56,830] INFO Partition [__consumer_offsets,39] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2016-11-22 15:57:56,830] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,39] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,830] INFO Truncating log __consumer_offsets-39 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:56,832] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,39], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,895] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:56,897] INFO Created log for partition [__consumer_offsets,36] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:56,897] INFO Partition [__consumer_offsets,36] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2016-11-22 15:57:56,897] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,36] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,898] INFO Truncating log __consumer_offsets-36 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:56,900] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,36], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:56,933] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [test1,1] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,058] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,060] INFO Created log for partition [__consumer_offsets,45] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,061] INFO Partition [__consumer_offsets,45] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2016-11-22 15:57:57,061] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,45] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,062] INFO Truncating log __consumer_offsets-45 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,064] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,45], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,081] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,084] INFO Created log for partition [__consumer_offsets,15] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,084] INFO Partition [__consumer_offsets,15] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2016-11-22 15:57:57,085] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,15] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,085] INFO Truncating log __consumer_offsets-15 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,086] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,15], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,113] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,115] INFO Created log for partition [__consumer_offsets,33] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,115] INFO Partition [__consumer_offsets,33] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2016-11-22 15:57:57,116] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,33] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,116] INFO Truncating log __consumer_offsets-33 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,118] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,33], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,189] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,191] INFO Created log for partition [__consumer_offsets,21] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,192] INFO Partition [__consumer_offsets,21] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2016-11-22 15:57:57,192] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,21] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,193] INFO Truncating log __consumer_offsets-21 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,195] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,21], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,208] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,210] INFO Created log for partition [__consumer_offsets,6] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,210] INFO Partition [__consumer_offsets,6] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2016-11-22 15:57:57,210] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,6] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,211] INFO Truncating log __consumer_offsets-6 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,213] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,6], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,265] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,266] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,378] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,379] INFO Created log for partition [__consumer_offsets,27] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,379] INFO Partition [__consumer_offsets,27] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2016-11-22 15:57:57,380] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,27] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,380] INFO Truncating log __consumer_offsets-27 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,383] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,27], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,436] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,439] INFO Created log for partition [__consumer_offsets,9] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,439] INFO Partition [__consumer_offsets,9] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2016-11-22 15:57:57,440] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,9] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,440] INFO Truncating log __consumer_offsets-9 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,442] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,9], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,502] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,504] INFO Created log for partition [__consumer_offsets,42] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,504] INFO Partition [__consumer_offsets,42] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2016-11-22 15:57:57,505] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,42] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,505] INFO Truncating log __consumer_offsets-42 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,508] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,42], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,549] INFO Completed load of log topic44-0 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,550] INFO Created log for partition [topic44,0] in /tmp/kafka-logs-2 with properties {compression.type -> producer, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> delete, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,551] INFO Partition [topic44,0] on broker 2: No checkpointed highwatermark is found for partition [topic44,0] (kafka.cluster.Partition)
[2016-11-22 15:57:57,551] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [topic44,0] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,552] INFO Truncating log topic44-0 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,555] ERROR [KafkaApi-2] error when handling request Name:LeaderAndIsrRequest;Version:0;Controller:0;ControllerEpoch:35;CorrelationId:113;ClientId:0;Leaders:BrokerEndPoint(1,localhost,9010);PartitionState:(topic44,0) -> (LeaderAndIsrInfo:(Leader:1,ISR:1,0,LeaderEpoch:27,ControllerEpoch:35),ReplicationFactor:3),AllReplicas:2,1,0) (kafka.server.KafkaApis)
java.lang.IllegalArgumentException: A metric named 'MetricName [name=connection-close-rate, group=replica-fetcher-metrics, description=Connections closed per second in the window., tags={broker-id=1, fetcher-id=0}]' already exists, can't register another one.
	at org.apache.kafka.common.metrics.Metrics.registerMetric(Metrics.java:285)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:177)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:162)
	at org.apache.kafka.common.network.Selector$SelectorMetrics.<init>(Selector.java:572)
	at org.apache.kafka.common.network.Selector.<init>(Selector.java:112)
	at kafka.server.ReplicaFetcherThread.<init>(ReplicaFetcherThread.scala:73)
	at kafka.server.ReplicaFetcherManager.createFetcherThread(ReplicaFetcherManager.scala:35)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:83)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:78)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.server.AbstractFetcherManager.addFetcherForPartitions(AbstractFetcherManager.scala:78)
	at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:816)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:641)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:131)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:72)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-22 15:57:57,653] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,655] INFO Created log for partition [__consumer_offsets,48] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,655] INFO Partition [__consumer_offsets,48] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2016-11-22 15:57:57,656] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,48] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,656] INFO Truncating log __consumer_offsets-48 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,658] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,48], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,717] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,719] INFO Created log for partition [__consumer_offsets,18] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,720] INFO Partition [__consumer_offsets,18] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2016-11-22 15:57:57,720] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,18] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,721] INFO Truncating log __consumer_offsets-18 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,723] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,18], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,768] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,769] INFO Created log for partition [__consumer_offsets,12] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,770] INFO Partition [__consumer_offsets,12] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2016-11-22 15:57:57,770] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,12] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,770] INFO Truncating log __consumer_offsets-12 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,772] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,12], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,780] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions  (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,782] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List() (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,902] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2016-11-22 15:57:57,904] INFO Created log for partition [__consumer_offsets,30] in /tmp/kafka-logs-2 with properties {compression.type -> uncompressed, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2016-11-22 15:57:57,904] INFO Partition [__consumer_offsets,30] on broker 2: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2016-11-22 15:57:57,905] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:57,905] INFO Truncating log __consumer_offsets-30 to offset 0. (kafka.log.Log)
[2016-11-22 15:57:57,907] INFO [ReplicaFetcherManager on broker 2] Added fetcher for partitions List([[__consumer_offsets,30], initOffset 0 to broker BrokerEndPoint(0,localhost,9009)] ) (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,378] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,3] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,382] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,3] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,396] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,3] in 14 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,400] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,3] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,435] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,24] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,435] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,24] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,440] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,24] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,442] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,24] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,569] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,570] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,0] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,575] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,0] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,579] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,0] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,781] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,39] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,782] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,39] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,785] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,39] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,788] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,39] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,811] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,36] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,811] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,36] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,815] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,36] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,815] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,36] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,861] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,45] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,861] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,45] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,864] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,45] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,866] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,45] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,887] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,15] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,888] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,15] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,892] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,15] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,895] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,15] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,918] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,33] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,918] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,33] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,927] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,33] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,929] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,33] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,979] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,21] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:58,980] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,21] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:58,989] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,21] in 9 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,001] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,21] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,109] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,6] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,110] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,6] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,117] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,6] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,139] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,6] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,398] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,27] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,398] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,27] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,404] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,27] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,406] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,27] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,433] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,9] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,434] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,9] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,439] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,9] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,442] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,9] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,509] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,42] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,510] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,42] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,514] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,42] in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,518] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,42] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,588] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,48] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,588] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,48] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,592] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,48] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,595] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,48] in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,615] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,18] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,616] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,18] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,621] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,18] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,623] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,18] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,737] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,12] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,737] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,12] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,744] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,12] in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,748] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,12] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,813] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,814] INFO [ReplicaFetcherThread-0-0], Shutting down (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:57:59,860] INFO [ReplicaFetcherThread-0-0], Stopped  (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:57:59,860] INFO [ReplicaFetcherThread-0-0], Shutdown completed (kafka.server.ReplicaFetcherThread)
[2016-11-22 15:57:59,863] INFO [Group Metadata Manager on Broker 2]: Loading offsets and group metadata from [__consumer_offsets,30] (kafka.coordinator.GroupMetadataManager)
[2016-11-22 15:57:59,865] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions [__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2016-11-22 15:57:59,869] INFO [Group Metadata Manager on Broker 2]: Finished loading offsets from [__consumer_offsets,30] in 6 milliseconds. (kafka.coordinator.GroupMetadataManager)
