[2016-11-17 18:11:54,235] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,28] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,48] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,5] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,21] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,18] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,23] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,9] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [othertopic,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,39] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [topic3,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,31] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [topic2,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,19] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,10] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [mytopic,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,22] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,43] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,40] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,27] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,6] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,252] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,47] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,30] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,42] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,41] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,3] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,13] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,4] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,16] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,46] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,49] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [topic4,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,14] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,45] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,37] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,29] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [othertopic,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,20] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,8] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [othertopic,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [topic2,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,38] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [topic2,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [othertopic,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,7] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [topic2,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,253] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,34] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [topic2,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,33] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,26] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [topic3,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,44] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,32] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,25] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,11] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [othertopic,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,36] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [othertopic,1] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,12] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,35] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,15] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,17] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [topic4,0] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [__consumer_offsets,24] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [topic2,2] from OnlineReplica to OnlineReplica (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 1 for partition [topic3,1] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 1 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:11:54,254] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition [topic4,0] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 1 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition [topic2,0] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:11:54,255] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 0 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 0 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 0 for partition [mytopic,0] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 0 for partition [topic4,0] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 0 for partition [topic3,0] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,0,1,LeaderEpoch:17,ControllerEpoch:53) to broker 0 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 0 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition [topic2,0] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 1 for partition topic3-1 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 1 for partition mytopic-0 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:54,256] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:54,257] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:54,257] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 1 for partition topic3-0 (state.change.logger)
[2016-11-17 18:11:54,257] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:54,257] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:17,ControllerEpoch:53) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:54,258] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:54,259] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:53,ControllerEpoch:53) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 0 for partition topic3-1 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:7,ControllerEpoch:59) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:54,260] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 0 for partition mytopic-0 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 0 for partition topic4-0 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 0 for partition topic3-0 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:33,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,0,1,LeaderEpoch:17,ControllerEpoch:53) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:54,261] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:49,ControllerEpoch:58) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:36,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:35,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:54,262] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,1,LeaderEpoch:35,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:54,263] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:54,264] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:54,264] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:53) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:54,264] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:34,ControllerEpoch:58) to broker 0 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:54,266] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=19,error_code=13},{topic=__consumer_offsets,partition=30,error_code=13},{topic=__consumer_offsets,partition=47,error_code=13},{topic=__consumer_offsets,partition=29,error_code=13},{topic=__consumer_offsets,partition=41,error_code=13},{topic=topic2,partition=1,error_code=13},{topic=__consumer_offsets,partition=39,error_code=13},{topic=__consumer_offsets,partition=17,error_code=13},{topic=__consumer_offsets,partition=10,error_code=13},{topic=__consumer_offsets,partition=14,error_code=13},{topic=topic3,partition=1,error_code=13},{topic=__consumer_offsets,partition=40,error_code=13},{topic=__consumer_offsets,partition=18,error_code=13},{topic=__consumer_offsets,partition=26,error_code=13},{topic=__consumer_offsets,partition=0,error_code=13},{topic=__consumer_offsets,partition=24,error_code=13},{topic=__consumer_offsets,partition=33,error_code=13},{topic=othertopic,partition=0,error_code=13},{topic=__consumer_offsets,partition=20,error_code=13},{topic=__consumer_offsets,partition=3,error_code=13},{topic=__consumer_offsets,partition=21,error_code=13},{topic=__consumer_offsets,partition=5,error_code=13},{topic=__consumer_offsets,partition=22,error_code=13},{topic=othertopic,partition=1,error_code=13},{topic=__consumer_offsets,partition=12,error_code=13},{topic=topic2,partition=0,error_code=13},{topic=__consumer_offsets,partition=8,error_code=13},{topic=__consumer_offsets,partition=23,error_code=13},{topic=__consumer_offsets,partition=15,error_code=13},{topic=__consumer_offsets,partition=11,error_code=13},{topic=__consumer_offsets,partition=48,error_code=13},{topic=__consumer_offsets,partition=13,error_code=13},{topic=__consumer_offsets,partition=49,error_code=13},{topic=__consumer_offsets,partition=6,error_code=13},{topic=__consumer_offsets,partition=28,error_code=13},{topic=__consumer_offsets,partition=4,error_code=13},{topic=__consumer_offsets,partition=37,error_code=13},{topic=__consumer_offsets,partition=31,error_code=13},{topic=__consumer_offsets,partition=44,error_code=13},{topic=__consumer_offsets,partition=42,error_code=13},{topic=__consumer_offsets,partition=34,error_code=13},{topic=__consumer_offsets,partition=46,error_code=13},{topic=__consumer_offsets,partition=25,error_code=13},{topic=__consumer_offsets,partition=45,error_code=13},{topic=__consumer_offsets,partition=27,error_code=13},{topic=__consumer_offsets,partition=32,error_code=13},{topic=topic2,partition=2,error_code=13},{topic=__consumer_offsets,partition=43,error_code=13},{topic=othertopic,partition=2,error_code=13},{topic=__consumer_offsets,partition=36,error_code=13},{topic=__consumer_offsets,partition=35,error_code=13},{topic=__consumer_offsets,partition=7,error_code=13},{topic=__consumer_offsets,partition=38,error_code=13},{topic=__consumer_offsets,partition=9,error_code=13},{topic=__consumer_offsets,partition=1,error_code=13},{topic=topic4,partition=0,error_code=13},{topic=__consumer_offsets,partition=16,error_code=13},{topic=__consumer_offsets,partition=2,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:54,267] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=1,error_code=13},{topic=othertopic,partition=0,error_code=13},{topic=topic2,partition=0,error_code=13},{topic=othertopic,partition=1,error_code=13},{topic=othertopic,partition=2,error_code=13},{topic=topic2,partition=2,error_code=13},{topic=mytopic,partition=0,error_code=13},{topic=topic3,partition=0,error_code=13},{topic=topic4,partition=0,error_code=13}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:54,267] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:11:54,272] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:54,275] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:54,431] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:11:54,432] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,19] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,432] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:11:54,469] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:11:54,471] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,30] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,471] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:11:54,473] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:11:54,474] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,47] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,474] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:11:54,476] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:11:54,477] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,29] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,477] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:11:54,480] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:11:54,481] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,41] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,481] TRACE Controller 2 epoch 60 started leader election for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:54,486] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:54,487] TRACE Controller 2 epoch 60 changed partition [topic2,1] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,487] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:11:54,491] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:11:54,492] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,39] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,492] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:11:54,495] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:11:54,497] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,17] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,497] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:11:54,504] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:11:54,505] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,10] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,505] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:11:54,509] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:11:54,510] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,14] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,510] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:11:54,592] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:11:54,593] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,40] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,593] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:11:54,654] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:11:54,655] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,18] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,655] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:11:54,660] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:11:54,661] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,0] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,661] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:11:54,664] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:11:54,664] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,26] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,665] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:11:54,668] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:11:54,669] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,24] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,669] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:11:54,670] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:11:54,671] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,33] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,671] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:54,674] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:54,674] TRACE Controller 2 epoch 60 changed partition [othertopic,0] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,674] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:11:54,677] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:11:54,678] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,20] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,678] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:11:54,679] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:11:54,680] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,21] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,680] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:11:54,682] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:11:54,682] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,3] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,682] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:11:54,684] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:11:54,685] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,5] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,685] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:11:54,687] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:11:54,688] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,22] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,688] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:54,690] TRACE Controller 2 epoch 60 elected leader 0 for Offline partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:54,691] TRACE Controller 2 epoch 60 changed partition [othertopic,1] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-11-17 18:11:54,691] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:11:54,694] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:11:54,694] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,12] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,694] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:11:54,849] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:11:54,850] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,8] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,850] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:11:54,891] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:11:54,892] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,23] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,892] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:11:54,895] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:11:54,895] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,15] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,895] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:11:54,899] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:11:54,899] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,48] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,899] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:11:54,901] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:11:54,902] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,11] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,902] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:11:54,904] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:11:54,905] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,13] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,905] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:11:54,908] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:11:54,908] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,6] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,908] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:11:54,910] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:11:54,910] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,49] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,911] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:11:54,913] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:11:54,914] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,4] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,914] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:11:54,917] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:11:54,917] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,28] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,917] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:11:54,919] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:11:54,919] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,37] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,919] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:11:54,921] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:11:54,921] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,31] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,921] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:11:54,925] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:11:54,926] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,44] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,926] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:11:54,929] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:11:54,930] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,42] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:54,931] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:11:55,014] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:11:55,015] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,34] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,015] TRACE Controller 2 epoch 60 started leader election for partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,017] ERROR Controller 2 epoch 60 initiated state change for partition [topic1,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [topic1,0] is alive. Live brokers are: [Set(0, 1)], Assigned replicas are: [List(2)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-11-17 18:11:55,018] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:11:55,079] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:11:55,079] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,46] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,079] TRACE Controller 2 epoch 60 started leader election for partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,081] ERROR Controller 2 epoch 60 initiated state change for partition [topic3,2] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [topic3,2] is alive. Live brokers are: [Set(0, 1)], Assigned replicas are: [List(2)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-11-17 18:11:55,083] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:11:55,085] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:11:55,085] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,25] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,085] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:11:55,087] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:11:55,087] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,27] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,087] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:11:55,089] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:11:55,090] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,45] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,090] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:11:55,093] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:11:55,094] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,32] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,094] TRACE Controller 2 epoch 60 started leader election for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:55,096] TRACE Controller 2 epoch 60 elected leader 0 for Offline partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:55,097] TRACE Controller 2 epoch 60 changed partition [topic2,2] from OfflinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-11-17 18:11:55,097] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:11:55,099] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:11:55,099] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,43] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,099] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:11:55,102] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:11:55,103] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,36] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,103] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:11:55,104] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:11:55,105] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,35] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,105] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:11:55,107] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:11:55,107] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,7] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,107] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:11:55,110] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:11:55,111] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,38] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,111] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:11:55,113] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:11:55,113] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,9] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,113] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:11:55,116] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:11:55,116] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,1] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,116] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:11:55,119] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:11:55,120] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,2] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,121] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:11:55,249] TRACE Controller 2 epoch 60 elected leader 1 for Offline partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 changed partition [__consumer_offsets,16] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 1 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 1 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:11:55,250] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 0 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 0 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,251] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,252] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,253] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,254] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,255] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,255] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 1 for partition topic3-1 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,304] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,305] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,305] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,305] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,305] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 1 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,305] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,305] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 1 for partition mytopic-0 (state.change.logger)
[2016-11-17 18:11:55,305] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,305] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 1 for partition topic3-0 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,306] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 1 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,307] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 0 for partition topic3-1 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 0 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 0 for partition mytopic-0 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 0 for partition topic4-0 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 0 for partition topic3-0 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,308] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 0 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,309] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,361] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,362] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,363] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 2 for partition topic3-1 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 2 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 2 for partition mytopic-0 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 2 for partition topic4-0 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 2 for partition topic3-0 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,411] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 2 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,412] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 1 for partition topic3-1 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 1 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 1 for partition mytopic-0 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 1 for partition topic3-0 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,413] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 1 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,32] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,16] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,414] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:0,2,1) for partition [topic2,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,49] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,44] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,28] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,1,0) for partition [topic2,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,17] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,23] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,7] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,4] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,29] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59),ReplicationFactor:2),AllReplicas:0,1) for partition [topic4,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,35] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,3] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,24] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,41] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52),ReplicationFactor:1),AllReplicas:2) for partition [topic1,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,38] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,13] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,8] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,5] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58) to broker 0 for partition topic3-1 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,39] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,36] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,415] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:7,ControllerEpoch:58),ReplicationFactor:1),AllReplicas:1) for partition [topic3,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,40] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,1,2) for partition [othertopic,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,45] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,15] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 0 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,33] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,37] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59) to broker 0 for partition mytopic-0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,21] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:59) to broker 0 for partition topic4-0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,6] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,11] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,20] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,47] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,27] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59) to broker 0 for partition topic3-0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52),ReplicationFactor:1),AllReplicas:2) for partition [topic3,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:38,ControllerEpoch:59),ReplicationFactor:1),AllReplicas:0) for partition [mytopic,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,34] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,9] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,22] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,42] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,416] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,14] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,25] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,10] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:1,0,2) for partition [topic2,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,48] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,31] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,18] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,19] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,12] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:5,ControllerEpoch:59),ReplicationFactor:1),AllReplicas:0) for partition [topic3,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,46] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,43] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,26] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,30] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:1,2,0) for partition [othertopic,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 0 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,417] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,418] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,418] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,418] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,418] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,418] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,17] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,38] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,39] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,23] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,48] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,42] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,22] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,13] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,34] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [othertopic,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,40] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,33] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,3] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,37] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,24] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,11] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,20] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,27] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,30] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [topic1,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,15] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,28] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,7] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,43] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,10] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,12] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,32] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,4] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,419] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,26] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,35] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,46] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,6] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,8] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,44] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,45] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [topic2,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [topic2,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [topic3,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,49] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,19] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,36] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,14] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [othertopic,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,31] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,21] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [othertopic,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,25] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,5] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,41] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,47] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,16] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [topic2,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,29] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,18] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,9] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-11-17 18:11:55,420] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 2 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 2 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 2 for partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 2 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 2 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 2 for partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition [topic2,0] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:11:55,421] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 2 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:0,2,1) correlation id 1 from controller 2 epoch 60 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:55,422] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,1,0) correlation id 1 from controller 2 epoch 60 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52),ReplicationFactor:1),AllReplicas:2) correlation id 1 from controller 2 epoch 60 for partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 2 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 1 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 1 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,424] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52) to broker 0 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52) to broker 0 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,425] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:11:55,423] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,1,2) correlation id 1 from controller 2 epoch 60 for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Controller 2 epoch 60 started leader election for partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) correlation id 1 from controller 2 epoch 60 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52),ReplicationFactor:1),AllReplicas:2) correlation id 1 from controller 2 epoch 60 for partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:11:55,426] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:1,0,2) correlation id 1 from controller 2 epoch 60 for partition [topic2,0] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 2 epoch 60 for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:1,2,0) correlation id 1 from controller 2 epoch 60 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:55,427] WARN Broker 2 ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 60 for partition [topic1,0] since its associated leader epoch 21 is old. Current leader epoch is 21 (state.change.logger)
[2016-11-17 18:11:55,427] WARN Broker 2 ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 60 for partition [othertopic,2] since its associated leader epoch 49 is old. Current leader epoch is 49 (state.change.logger)
[2016-11-17 18:11:55,427] WARN Broker 2 ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 60 for partition [topic3,2] since its associated leader epoch 5 is old. Current leader epoch is 5 (state.change.logger)
[2016-11-17 18:11:55,427] WARN Broker 2 ignoring LeaderAndIsr request from controller 2 with correlation id 1 epoch 60 for partition [topic2,0] since its associated leader epoch 15 is old. Current leader epoch is 15 (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:11:55,427] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:11:55,428] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:11:55,429] TRACE Broker 2 handling LeaderAndIsr request correlationId 1 from controller 2 epoch 60 starting the become-follower transition for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:11:55,435] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:11:55,436] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:11:55,437] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:11:55,437] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:11:55,437] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 1 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Controller 2 epoch 60 elected leader 2 for Offline partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,22] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,25] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [othertopic,1] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,31] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,34] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,37] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,40] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,43] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,46] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,49] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,28] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [topic2,2] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,41] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,44] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,47] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,1] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,4] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,7] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,10] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,13] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,483] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,16] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,484] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,19] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,484] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,2] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,484] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,5] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,8] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,11] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,14] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,17] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,20] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,23] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,26] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,29] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,484] TRACE Controller 2 epoch 60 changed partition [topic1,0] from OfflinePartition to OnlinePartition with leader 2 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,32] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,35] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Controller 2 epoch 60 started leader election for partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,38] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,0] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,3] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,6] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,9] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,12] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,15] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,18] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,21] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,24] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [othertopic,0] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,30] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,33] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,36] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,39] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,42] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,45] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,48] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [__consumer_offsets,27] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,485] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [topic2,1] as part of become-follower request with correlation id 1 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:11:55,488] TRACE Controller 2 epoch 60 elected leader 2 for Offline partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,489] TRACE Controller 2 epoch 60 changed partition [topic3,2] from OfflinePartition to OnlinePartition with leader 2 (state.change.logger)
[2016-11-17 18:11:55,489] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:22,ControllerEpoch:60) to broker 2 for partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,490] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:2,ISR:2,LeaderEpoch:6,ControllerEpoch:60) to broker 2 for partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,490] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:22,ControllerEpoch:60) to broker 2 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,490] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:6,ControllerEpoch:60) to broker 2 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,490] ERROR Error on broker 2 while processing LeaderAndIsr request with correlationId 1 received from controller 2 epoch 60 (state.change.logger)
java.lang.IllegalArgumentException: A metric named 'MetricName [name=connection-close-rate, group=replica-fetcher-metrics, description=Connections closed per second in the window., tags={broker-id=1, fetcher-id=0}]' already exists, can't register another one.
	at org.apache.kafka.common.metrics.Metrics.registerMetric(Metrics.java:285)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:177)
	at org.apache.kafka.common.metrics.Sensor.add(Sensor.java:162)
	at org.apache.kafka.common.network.Selector$SelectorMetrics.<init>(Selector.java:572)
	at org.apache.kafka.common.network.Selector.<init>(Selector.java:112)
	at kafka.server.ReplicaFetcherThread.<init>(ReplicaFetcherThread.scala:73)
	at kafka.server.ReplicaFetcherManager.createFetcherThread(ReplicaFetcherManager.scala:35)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:83)
	at kafka.server.AbstractFetcherManager$$anonfun$addFetcherForPartitions$2.apply(AbstractFetcherManager.scala:78)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.server.AbstractFetcherManager.addFetcherForPartitions(AbstractFetcherManager.scala:78)
	at kafka.server.ReplicaManager.makeFollowers(ReplicaManager.scala:816)
	at kafka.server.ReplicaManager.becomeLeaderOrFollower(ReplicaManager.scala:641)
	at kafka.server.KafkaApis.handleLeaderAndIsrRequest(KafkaApis.scala:131)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:72)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
[2016-11-17 18:11:55,490] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:22,ControllerEpoch:60) to broker 1 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,490] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:6,ControllerEpoch:60) to broker 1 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,491] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:22,ControllerEpoch:60) to broker 0 for partition topic1-0 (state.change.logger)
[2016-11-17 18:11:55,491] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:2,LeaderEpoch:6,ControllerEpoch:60) to broker 0 for partition topic3-2 (state.change.logger)
[2016-11-17 18:11:55,492] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=32,error_code=-1},{topic=__consumer_offsets,partition=16,error_code=-1},{topic=topic2,partition=2,error_code=-1},{topic=__consumer_offsets,partition=49,error_code=-1},{topic=__consumer_offsets,partition=44,error_code=-1},{topic=__consumer_offsets,partition=28,error_code=-1},{topic=topic2,partition=1,error_code=-1},{topic=__consumer_offsets,partition=17,error_code=-1},{topic=__consumer_offsets,partition=23,error_code=-1},{topic=__consumer_offsets,partition=7,error_code=-1},{topic=__consumer_offsets,partition=4,error_code=-1},{topic=__consumer_offsets,partition=29,error_code=-1},{topic=__consumer_offsets,partition=35,error_code=-1},{topic=__consumer_offsets,partition=3,error_code=-1},{topic=__consumer_offsets,partition=24,error_code=-1},{topic=__consumer_offsets,partition=41,error_code=-1},{topic=topic1,partition=0,error_code=-1},{topic=__consumer_offsets,partition=0,error_code=-1},{topic=__consumer_offsets,partition=38,error_code=-1},{topic=__consumer_offsets,partition=13,error_code=-1},{topic=__consumer_offsets,partition=8,error_code=-1},{topic=__consumer_offsets,partition=5,error_code=-1},{topic=__consumer_offsets,partition=39,error_code=-1},{topic=__consumer_offsets,partition=36,error_code=-1},{topic=__consumer_offsets,partition=40,error_code=-1},{topic=othertopic,partition=2,error_code=-1},{topic=__consumer_offsets,partition=45,error_code=-1},{topic=__consumer_offsets,partition=15,error_code=-1},{topic=__consumer_offsets,partition=33,error_code=-1},{topic=__consumer_offsets,partition=37,error_code=-1},{topic=__consumer_offsets,partition=21,error_code=-1},{topic=othertopic,partition=1,error_code=-1},{topic=__consumer_offsets,partition=6,error_code=-1},{topic=__consumer_offsets,partition=11,error_code=-1},{topic=__consumer_offsets,partition=20,error_code=-1},{topic=__consumer_offsets,partition=47,error_code=-1},{topic=__consumer_offsets,partition=2,error_code=-1},{topic=__consumer_offsets,partition=27,error_code=-1},{topic=topic3,partition=2,error_code=-1},{topic=__consumer_offsets,partition=34,error_code=-1},{topic=__consumer_offsets,partition=9,error_code=-1},{topic=__consumer_offsets,partition=22,error_code=-1},{topic=__consumer_offsets,partition=42,error_code=-1},{topic=__consumer_offsets,partition=14,error_code=-1},{topic=__consumer_offsets,partition=25,error_code=-1},{topic=__consumer_offsets,partition=10,error_code=-1},{topic=topic2,partition=0,error_code=-1},{topic=__consumer_offsets,partition=48,error_code=-1},{topic=__consumer_offsets,partition=31,error_code=-1},{topic=__consumer_offsets,partition=18,error_code=-1},{topic=__consumer_offsets,partition=19,error_code=-1},{topic=__consumer_offsets,partition=12,error_code=-1},{topic=__consumer_offsets,partition=46,error_code=-1},{topic=__consumer_offsets,partition=43,error_code=-1},{topic=__consumer_offsets,partition=1,error_code=-1},{topic=__consumer_offsets,partition=26,error_code=-1},{topic=__consumer_offsets,partition=30,error_code=-1},{topic=othertopic,partition=0,error_code=-1}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,32] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,16] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,LeaderEpoch:8,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:0,2,1) for partition [topic2,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,49] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,44] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,28] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,1,0) for partition [topic2,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,17] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,23] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,7] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,4] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,29] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,35] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,3] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,24] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,41] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:21,ControllerEpoch:52),ReplicationFactor:1),AllReplicas:2) for partition [topic1,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,38] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,13] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,8] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,5] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,493] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,39] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,36] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,40] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,1,2) for partition [othertopic,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,45] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,15] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,33] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,37] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,21] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,LeaderEpoch:54,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,6] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,11] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,20] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,47] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,27] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:5,ControllerEpoch:52),ReplicationFactor:1),AllReplicas:2) for partition [topic3,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,34] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,9] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,22] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,42] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,14] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,25] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,10] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:1,0,2) for partition [topic2,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,48] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,494] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,31] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,18] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,19] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,12] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,46] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,43] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,26] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,30] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:1,2,0) for partition [othertopic,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 2 (state.change.logger)
[2016-11-17 18:11:55,495] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:11:55,496] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:22,ControllerEpoch:60),ReplicationFactor:1),AllReplicas:2) correlation id 3 from controller 2 epoch 60 for partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,496] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:6,ControllerEpoch:60),ReplicationFactor:1),AllReplicas:2) correlation id 3 from controller 2 epoch 60 for partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,496] TRACE Broker 2 handling LeaderAndIsr request correlationId 3 from controller 2 epoch 60 starting the become-leader transition for partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,496] TRACE Broker 2 handling LeaderAndIsr request correlationId 3 from controller 2 epoch 60 starting the become-leader transition for partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,496] INFO Broker 2 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 2 epoch 60 for partition [topic1,0] since it is already the leader for the partition. (state.change.logger)
[2016-11-17 18:11:55,496] INFO Broker 2 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 2 epoch 60 for partition [topic3,2] since it is already the leader for the partition. (state.change.logger)
[2016-11-17 18:11:55,496] TRACE Broker 2 completed LeaderAndIsr request correlationId 3 from controller 2 epoch 60 for the become-leader transition for partition [topic1,0] (state.change.logger)
[2016-11-17 18:11:55,496] TRACE Broker 2 completed LeaderAndIsr request correlationId 3 from controller 2 epoch 60 for the become-leader transition for partition [topic3,2] (state.change.logger)
[2016-11-17 18:11:55,496] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic1,partition=0,error_code=0},{topic=topic3,partition=2,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:11:55,497] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:22,ControllerEpoch:60),ReplicationFactor:1),AllReplicas:2) for partition [topic1,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 4 (state.change.logger)
[2016-11-17 18:11:55,497] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:2,LeaderEpoch:6,ControllerEpoch:60),ReplicationFactor:1),AllReplicas:2) for partition [topic3,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 4 (state.change.logger)
[2016-11-17 18:11:55,497] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:11:55,501] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=1,error_code=0},{topic=othertopic,partition=0,error_code=0},{topic=othertopic,partition=1,error_code=0},{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:55,504] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:55,506] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:55,508] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:55,511] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:55,514] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:55,515] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:11:55,725] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=19,error_code=0},{topic=__consumer_offsets,partition=30,error_code=0},{topic=__consumer_offsets,partition=47,error_code=0},{topic=__consumer_offsets,partition=29,error_code=0},{topic=__consumer_offsets,partition=41,error_code=0},{topic=topic2,partition=1,error_code=0},{topic=__consumer_offsets,partition=39,error_code=0},{topic=__consumer_offsets,partition=17,error_code=0},{topic=__consumer_offsets,partition=10,error_code=0},{topic=__consumer_offsets,partition=14,error_code=0},{topic=__consumer_offsets,partition=40,error_code=0},{topic=__consumer_offsets,partition=18,error_code=0},{topic=__consumer_offsets,partition=0,error_code=0},{topic=__consumer_offsets,partition=26,error_code=0},{topic=__consumer_offsets,partition=24,error_code=0},{topic=__consumer_offsets,partition=33,error_code=0},{topic=othertopic,partition=0,error_code=0},{topic=__consumer_offsets,partition=20,error_code=0},{topic=__consumer_offsets,partition=3,error_code=0},{topic=__consumer_offsets,partition=21,error_code=0},{topic=__consumer_offsets,partition=5,error_code=0},{topic=__consumer_offsets,partition=22,error_code=0},{topic=othertopic,partition=1,error_code=0},{topic=__consumer_offsets,partition=12,error_code=0},{topic=__consumer_offsets,partition=8,error_code=0},{topic=__consumer_offsets,partition=23,error_code=0},{topic=__consumer_offsets,partition=15,error_code=0},{topic=__consumer_offsets,partition=11,error_code=0},{topic=__consumer_offsets,partition=48,error_code=0},{topic=__consumer_offsets,partition=13,error_code=0},{topic=__consumer_offsets,partition=49,error_code=0},{topic=__consumer_offsets,partition=6,error_code=0},{topic=__consumer_offsets,partition=4,error_code=0},{topic=__consumer_offsets,partition=28,error_code=0},{topic=__consumer_offsets,partition=37,error_code=0},{topic=__consumer_offsets,partition=31,error_code=0},{topic=__consumer_offsets,partition=44,error_code=0},{topic=__consumer_offsets,partition=42,error_code=0},{topic=__consumer_offsets,partition=34,error_code=0},{topic=__consumer_offsets,partition=46,error_code=0},{topic=__consumer_offsets,partition=25,error_code=0},{topic=__consumer_offsets,partition=27,error_code=0},{topic=__consumer_offsets,partition=45,error_code=0},{topic=topic2,partition=2,error_code=0},{topic=__consumer_offsets,partition=32,error_code=0},{topic=__consumer_offsets,partition=43,error_code=0},{topic=__consumer_offsets,partition=36,error_code=0},{topic=__consumer_offsets,partition=35,error_code=0},{topic=__consumer_offsets,partition=7,error_code=0},{topic=__consumer_offsets,partition=9,error_code=0},{topic=__consumer_offsets,partition=38,error_code=0},{topic=__consumer_offsets,partition=1,error_code=0},{topic=__consumer_offsets,partition=2,error_code=0},{topic=__consumer_offsets,partition=16,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:55,734] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:55,738] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:55,740] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:55,743] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:55,749] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:55,751] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:57,555] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:54,ControllerEpoch:60) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:57,555] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:8,ControllerEpoch:60) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:57,555] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:54,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:57,555] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:8,ControllerEpoch:60) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:57,555] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:54,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:11:57,555] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,2,LeaderEpoch:8,ControllerEpoch:60) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 18:11:57,556] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:54,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 5 (state.change.logger)
[2016-11-17 18:11:57,556] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,2,LeaderEpoch:8,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:0,2,1) for partition [topic2,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 5 (state.change.logger)
[2016-11-17 18:11:57,556] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:11:57,557] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:11:57,557] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:12:00,314] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:12:00,316] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,19] due to: Preferred replica 2 for partition [__consumer_offsets,19] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,316] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,19] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,19] due to: Preferred replica 2 for partition [__consumer_offsets,19] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,19] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,318] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:12:00,320] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,47] due to: Preferred replica 2 for partition [__consumer_offsets,47] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,320] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,47] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,47] due to: Preferred replica 2 for partition [__consumer_offsets,47] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,47] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,320] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:12:00,322] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,29] due to: Preferred replica 2 for partition [__consumer_offsets,29] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,322] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,29] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,29] due to: Preferred replica 2 for partition [__consumer_offsets,29] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,29] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,322] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:12:00,324] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,41] due to: Preferred replica 2 for partition [__consumer_offsets,41] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,324] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,41] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,41] due to: Preferred replica 2 for partition [__consumer_offsets,41] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,41] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,324] TRACE Controller 2 epoch 60 started leader election for partition [topic2,1] (state.change.logger)
[2016-11-17 18:12:00,326] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [topic2,1] due to: Preferred replica 2 for partition [topic2,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":18,"isr":[0,1]}]. (state.change.logger)
[2016-11-17 18:12:00,326] ERROR Controller 2 epoch 60 initiated state change for partition [topic2,1] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,1] due to: Preferred replica 2 for partition [topic2,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":18,"isr":[0,1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [topic2,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":18,"isr":[0,1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,326] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:12:00,328] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,39] due to: Preferred replica 2 for partition [__consumer_offsets,39] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,328] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,39] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,39] due to: Preferred replica 2 for partition [__consumer_offsets,39] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,39] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,328] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:12:00,329] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,17] due to: Preferred replica 2 for partition [__consumer_offsets,17] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,329] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,17] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,17] due to: Preferred replica 2 for partition [__consumer_offsets,17] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,17] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,330] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:12:00,332] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,33] due to: Preferred replica 2 for partition [__consumer_offsets,33] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,332] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,33] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,33] due to: Preferred replica 2 for partition [__consumer_offsets,33] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,33] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,333] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:12:00,334] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,3] due to: Preferred replica 2 for partition [__consumer_offsets,3] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,334] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,3] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,3] due to: Preferred replica 2 for partition [__consumer_offsets,3] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,3] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,335] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:12:00,336] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,21] due to: Preferred replica 2 for partition [__consumer_offsets,21] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,336] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,21] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,21] due to: Preferred replica 2 for partition [__consumer_offsets,21] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,21] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,337] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:12:00,339] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,5] due to: Preferred replica 2 for partition [__consumer_offsets,5] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,339] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,5] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,5] due to: Preferred replica 2 for partition [__consumer_offsets,5] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,5] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,339] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,341] TRACE Controller 2 epoch 60 elected leader 2 for Offline partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,341] TRACE Controller 2 epoch 60 changed partition [othertopic,1] from OnlinePartition to OnlinePartition with leader 2 (state.change.logger)
[2016-11-17 18:12:00,342] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 2 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,342] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 1 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,342] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 0 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,342] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:12:00,342] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:12:00,342] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) correlation id 6 from controller 2 epoch 60 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,342] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:12:00,342] TRACE Broker 2 handling LeaderAndIsr request correlationId 6 from controller 2 epoch 60 starting the become-leader transition for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,343] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:12:00,344] TRACE Broker 2 stopped fetchers as part of become-leader request from controller 2 epoch 60 with correlation id 6 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,344] TRACE Broker 2 completed LeaderAndIsr request correlationId 6 from controller 2 epoch 60 for the become-leader transition for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:12:00,345] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:12:00,345] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 7 (state.change.logger)
[2016-11-17 18:12:00,346] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:12:00,347] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,23] due to: Preferred replica 2 for partition [__consumer_offsets,23] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,347] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,23] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,23] due to: Preferred replica 2 for partition [__consumer_offsets,23] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,23] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,348] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:12:00,348] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:12:00,350] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:12:00,351] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,15] due to: Preferred replica 2 for partition [__consumer_offsets,15] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,352] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,15] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,15] due to: Preferred replica 2 for partition [__consumer_offsets,15] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,15] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,352] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:12:00,352] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:12:00,353] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:12:00,356] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,11] due to: Preferred replica 2 for partition [__consumer_offsets,11] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,356] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,11] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,11] due to: Preferred replica 2 for partition [__consumer_offsets,11] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,11] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,357] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:12:00,358] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,13] due to: Preferred replica 2 for partition [__consumer_offsets,13] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,358] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,13] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,13] due to: Preferred replica 2 for partition [__consumer_offsets,13] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,13] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,358] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:12:00,359] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,49] due to: Preferred replica 2 for partition [__consumer_offsets,49] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,360] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,49] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,49] due to: Preferred replica 2 for partition [__consumer_offsets,49] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,49] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,360] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:12:00,361] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,37] due to: Preferred replica 2 for partition [__consumer_offsets,37] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,361] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,37] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,37] due to: Preferred replica 2 for partition [__consumer_offsets,37] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,37] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,362] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:12:00,363] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,31] due to: Preferred replica 2 for partition [__consumer_offsets,31] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,363] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,31] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,31] due to: Preferred replica 2 for partition [__consumer_offsets,31] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,31] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,364] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:12:00,365] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,25] due to: Preferred replica 2 for partition [__consumer_offsets,25] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,365] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,25] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,25] due to: Preferred replica 2 for partition [__consumer_offsets,25] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,25] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,366] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:12:00,367] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,45] due to: Preferred replica 2 for partition [__consumer_offsets,45] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,367] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,45] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,45] due to: Preferred replica 2 for partition [__consumer_offsets,45] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,45] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,368] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:12:00,369] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,27] due to: Preferred replica 2 for partition [__consumer_offsets,27] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,369] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,27] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,27] due to: Preferred replica 2 for partition [__consumer_offsets,27] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,27] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,370] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:12:00,371] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,43] due to: Preferred replica 2 for partition [__consumer_offsets,43] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,371] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,43] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,43] due to: Preferred replica 2 for partition [__consumer_offsets,43] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,43] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,371] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:12:00,372] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,35] due to: Preferred replica 2 for partition [__consumer_offsets,35] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,372] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,35] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,35] due to: Preferred replica 2 for partition [__consumer_offsets,35] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,35] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,373] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:12:00,374] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,7] due to: Preferred replica 2 for partition [__consumer_offsets,7] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,374] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,7] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,7] due to: Preferred replica 2 for partition [__consumer_offsets,7] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,7] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,374] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:12:00,375] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,9] due to: Preferred replica 2 for partition [__consumer_offsets,9] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,375] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,9] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,9] due to: Preferred replica 2 for partition [__consumer_offsets,9] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,9] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,376] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:12:00,377] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,1] due to: Preferred replica 2 for partition [__consumer_offsets,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,377] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,1] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,1] due to: Preferred replica 2 for partition [__consumer_offsets,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,377] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:12:00,378] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [othertopic,2] due to: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}]. (state.change.logger)
[2016-11-17 18:12:00,378] ERROR Controller 2 epoch 60 initiated state change for partition [othertopic,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,2] due to: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,379] TRACE Controller 2 epoch 60 started leader election for partition [topic4,0] (state.change.logger)
[2016-11-17 18:12:00,380] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [topic4,0] due to: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:12:00,380] ERROR Controller 2 epoch 60 initiated state change for partition [topic4,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic4,0] due to: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:12:00,893] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:12:00,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,49] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,1,0) for partition [topic2,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,17] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,23] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,7] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,29] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,35] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,3] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,41] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,13] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,5] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,39] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,45] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,15] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,33] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,37] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,21] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:2,ISR:0,1,2,LeaderEpoch:55,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,11] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,47] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,895] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,27] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,9] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,25] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,31] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,19] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,43] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 8 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:12:00,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:12:00,897] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:12:00,899] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:12:01,025] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:1,2,0) for partition [othertopic,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 9 (state.change.logger)
[2016-11-17 18:12:01,026] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:15,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:1,0,2) for partition [topic2,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 9 (state.change.logger)
[2016-11-17 18:12:01,026] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:49,ControllerEpoch:59),ReplicationFactor:3),AllReplicas:0,1,2) for partition [othertopic,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 9 (state.change.logger)
[2016-11-17 18:12:01,026] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:12:01,026] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:12:01,026] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:17:00,324] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:17:00,331] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,19] due to: Preferred replica 2 for partition [__consumer_offsets,19] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,331] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,19] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,19] due to: Preferred replica 2 for partition [__consumer_offsets,19] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,19] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,332] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:17:00,333] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,47] due to: Preferred replica 2 for partition [__consumer_offsets,47] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,333] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,47] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,47] due to: Preferred replica 2 for partition [__consumer_offsets,47] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,47] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,334] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:17:00,335] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,29] due to: Preferred replica 2 for partition [__consumer_offsets,29] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,335] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,29] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,29] due to: Preferred replica 2 for partition [__consumer_offsets,29] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,29] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,335] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:17:00,337] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,41] due to: Preferred replica 2 for partition [__consumer_offsets,41] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,337] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,41] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,41] due to: Preferred replica 2 for partition [__consumer_offsets,41] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,41] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,337] TRACE Controller 2 epoch 60 started leader election for partition [topic2,1] (state.change.logger)
[2016-11-17 18:17:00,338] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [topic2,1] due to: Preferred replica 2 for partition [topic2,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":18,"isr":[0,1]}]. (state.change.logger)
[2016-11-17 18:17:00,338] ERROR Controller 2 epoch 60 initiated state change for partition [topic2,1] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,1] due to: Preferred replica 2 for partition [topic2,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":18,"isr":[0,1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [topic2,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":18,"isr":[0,1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,339] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:17:00,340] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,39] due to: Preferred replica 2 for partition [__consumer_offsets,39] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,340] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,39] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,39] due to: Preferred replica 2 for partition [__consumer_offsets,39] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,39] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,340] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:17:00,341] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,17] due to: Preferred replica 2 for partition [__consumer_offsets,17] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,341] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,17] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,17] due to: Preferred replica 2 for partition [__consumer_offsets,17] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,17] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,342] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:17:00,343] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,33] due to: Preferred replica 2 for partition [__consumer_offsets,33] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,343] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,33] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,33] due to: Preferred replica 2 for partition [__consumer_offsets,33] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,33] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,344] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:17:00,345] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,3] due to: Preferred replica 2 for partition [__consumer_offsets,3] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,345] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,3] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,3] due to: Preferred replica 2 for partition [__consumer_offsets,3] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,3] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,345] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:17:00,346] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,21] due to: Preferred replica 2 for partition [__consumer_offsets,21] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,346] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,21] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,21] due to: Preferred replica 2 for partition [__consumer_offsets,21] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,21] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,347] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:17:00,348] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,5] due to: Preferred replica 2 for partition [__consumer_offsets,5] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,348] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,5] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,5] due to: Preferred replica 2 for partition [__consumer_offsets,5] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,5] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,348] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:17:00,349] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,15] due to: Preferred replica 2 for partition [__consumer_offsets,15] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,349] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,15] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,15] due to: Preferred replica 2 for partition [__consumer_offsets,15] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,15] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,350] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:17:00,351] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,23] due to: Preferred replica 2 for partition [__consumer_offsets,23] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,351] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,23] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,23] due to: Preferred replica 2 for partition [__consumer_offsets,23] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,23] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,351] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:17:00,352] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,11] due to: Preferred replica 2 for partition [__consumer_offsets,11] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,352] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,11] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,11] due to: Preferred replica 2 for partition [__consumer_offsets,11] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,11] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,353] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:17:00,354] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,13] due to: Preferred replica 2 for partition [__consumer_offsets,13] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,354] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,13] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,13] due to: Preferred replica 2 for partition [__consumer_offsets,13] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,13] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,354] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:17:00,355] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,49] due to: Preferred replica 2 for partition [__consumer_offsets,49] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,355] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,49] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,49] due to: Preferred replica 2 for partition [__consumer_offsets,49] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,49] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,356] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:17:00,357] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,37] due to: Preferred replica 2 for partition [__consumer_offsets,37] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,357] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,37] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,37] due to: Preferred replica 2 for partition [__consumer_offsets,37] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,37] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,357] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:17:00,358] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,31] due to: Preferred replica 2 for partition [__consumer_offsets,31] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,358] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,31] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,31] due to: Preferred replica 2 for partition [__consumer_offsets,31] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,31] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":35,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,359] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:17:00,360] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,25] due to: Preferred replica 2 for partition [__consumer_offsets,25] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,360] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,25] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,25] due to: Preferred replica 2 for partition [__consumer_offsets,25] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,25] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,361] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:17:00,362] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,45] due to: Preferred replica 2 for partition [__consumer_offsets,45] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,362] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,45] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,45] due to: Preferred replica 2 for partition [__consumer_offsets,45] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,45] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,363] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:17:00,364] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,27] due to: Preferred replica 2 for partition [__consumer_offsets,27] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,364] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,27] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,27] due to: Preferred replica 2 for partition [__consumer_offsets,27] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,27] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,365] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:17:00,366] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,43] due to: Preferred replica 2 for partition [__consumer_offsets,43] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,366] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,43] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,43] due to: Preferred replica 2 for partition [__consumer_offsets,43] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,43] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,367] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:17:00,368] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,35] due to: Preferred replica 2 for partition [__consumer_offsets,35] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,368] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,35] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,35] due to: Preferred replica 2 for partition [__consumer_offsets,35] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,35] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,368] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:17:00,369] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,7] due to: Preferred replica 2 for partition [__consumer_offsets,7] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,369] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,7] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,7] due to: Preferred replica 2 for partition [__consumer_offsets,7] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,7] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":36,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,370] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:17:00,371] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,9] due to: Preferred replica 2 for partition [__consumer_offsets,9] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,371] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,9] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,9] due to: Preferred replica 2 for partition [__consumer_offsets,9] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,9] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,371] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:17:00,372] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,1] due to: Preferred replica 2 for partition [__consumer_offsets,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,372] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,1] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,1] due to: Preferred replica 2 for partition [__consumer_offsets,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [__consumer_offsets,1] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":37,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,373] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:17:00,374] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [othertopic,2] due to: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}]. (state.change.logger)
[2016-11-17 18:17:00,374] ERROR Controller 2 epoch 60 initiated state change for partition [othertopic,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,2] due to: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [othertopic,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":49,"isr":[1,2]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:17:00,374] TRACE Controller 2 epoch 60 started leader election for partition [topic4,0] (state.change.logger)
[2016-11-17 18:17:00,375] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [topic4,0] due to: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}]. (state.change.logger)
[2016-11-17 18:17:00,376] ERROR Controller 2 epoch 60 initiated state change for partition [topic4,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic4,0] due to: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map3.foreach(Map.scala:161)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 0 for partition [topic4,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":4,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-11-17 18:19:19,947] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:19:19,953] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,40] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:19,973] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:19:19,973] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:19:19,973] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:19:19,973] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:19:19,973] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-40 (state.change.logger)
[2016-11-17 18:19:19,974] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=40,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:19,974] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,40] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 11 (state.change.logger)
[2016-11-17 18:19:19,975] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:19,977] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,39] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:19,993] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:19:19,993] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:19:19,993] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:19:19,993] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-39 (state.change.logger)
[2016-11-17 18:19:19,994] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:19:19,994] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:19:19,994] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=40,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:19,995] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:19:19,995] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:19:19,995] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=39,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:19,995] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,39] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 14 (state.change.logger)
[2016-11-17 18:19:19,996] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:19,996] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:19:19,996] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:19:19,997] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=39,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:19,997] TRACE Broker 2 handling stop replica (delete=false) for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:19,998] TRACE Broker 2 finished handling stop replica (delete=false) for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:19,998] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,007] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=40,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,009] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,011] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=39,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,011] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,016] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,018] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,074] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [topic2,2] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,074] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,LeaderEpoch:9,ControllerEpoch:60) to broker 1 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:20,075] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,LeaderEpoch:9,ControllerEpoch:60) to broker 0 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:20,075] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:9,ControllerEpoch:60) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 18:19:20,075] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:9,ControllerEpoch:60) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 18:19:20,075] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:9,ControllerEpoch:60) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 18:19:20,076] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,LeaderEpoch:9,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:0,2,1) for partition [topic2,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 17 (state.change.logger)
[2016-11-17 18:19:20,076] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,366] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,367] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,369] TRACE Broker 2 handling stop replica (delete=false) for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:20,369] TRACE Broker 2 finished handling stop replica (delete=false) for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:20,370] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,370] TRACE Broker 2 handling stop replica (delete=false) for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,370] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [topic2,1] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,370] TRACE Broker 2 finished handling stop replica (delete=false) for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,370] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,370] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,370] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=1,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,371] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=1,error_code=13}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,370] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 18:19:20,384] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:19:20,384] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:19:20,386] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:0,1,LeaderEpoch:18,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,1,0) for partition [topic2,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 20 (state.change.logger)
[2016-11-17 18:19:20,386] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,387] TRACE Broker 2 handling stop replica (delete=false) for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,387] TRACE Broker 2 finished handling stop replica (delete=false) for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,388] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,388] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=1,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,388] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:19:20,388] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:19:20,389] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=32,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,390] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,32] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,390] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:19:20,390] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:19:20,390] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:19:20,390] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-32 (state.change.logger)
[2016-11-17 18:19:20,393] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,32] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 23 (state.change.logger)
[2016-11-17 18:19:20,393] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,393] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,400] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:19:20,400] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:19:20,400] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=32,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,401] TRACE Broker 2 handling stop replica (delete=false) for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:20,401] TRACE Broker 2 finished handling stop replica (delete=false) for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:20,401] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=2,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,407] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [othertopic,2] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,408] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:20,408] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:20,408] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:19:20,408] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:19:20,408] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:19:20,410] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:0,1,2) for partition [othertopic,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 26 (state.change.logger)
[2016-11-17 18:19:20,410] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,411] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,411] TRACE Broker 2 handling stop replica (delete=false) for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:20,411] TRACE Broker 2 finished handling stop replica (delete=false) for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:20,427] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=2,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,427] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,429] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,13] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,429] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:19:20,429] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:19:20,466] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=1,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,429] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:19:20,496] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:19:20,497] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=13,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,498] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,13] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 29 (state.change.logger)
[2016-11-17 18:19:20,499] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,499] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:19:20,499] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-13 (state.change.logger)
[2016-11-17 18:19:20,501] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:19:20,501] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:19:20,501] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=13,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,502] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:19:20,502] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:19:20,502] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=21,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,504] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,21] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,504] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:19:20,504] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:19:20,504] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:19:20,505] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-21 (state.change.logger)
[2016-11-17 18:19:20,505] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,21] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 32 (state.change.logger)
[2016-11-17 18:19:20,535] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,535] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,536] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:19:20,536] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:19:20,536] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=21,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,536] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=2,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,537] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=32,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,537] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:19:20,508] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,12] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,537] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:19:20,537] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=12,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,537] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,538] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,538] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:19:20,538] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,538] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:19:20,540] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,540] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=2,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,540] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,12] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 35 (state.change.logger)
[2016-11-17 18:19:20,540] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,540] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,540] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:19:20,542] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=13,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,586] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-12 (state.change.logger)
[2016-11-17 18:19:20,587] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,588] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=21,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,589] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,593] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:19:20,593] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:19:20,594] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=12,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,595] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:19:20,595] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:19:20,595] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=7,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,620] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,621] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=12,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,622] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,622] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,7] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,622] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:19:20,623] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:19:20,623] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:19:20,623] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-7 (state.change.logger)
[2016-11-17 18:19:20,624] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,7] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 38 (state.change.logger)
[2016-11-17 18:19:20,626] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,18] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,664] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:19:20,664] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:19:20,664] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:19:20,664] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-18 (state.change.logger)
[2016-11-17 18:19:20,625] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,667] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,625] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=7,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,668] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,669] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:19:20,669] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:19:20,672] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=7,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,672] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,672] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,24] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,673] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:19:20,673] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:19:20,673] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:19:20,673] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:19:20,673] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:19:20,673] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-24 (state.change.logger)
[2016-11-17 18:19:20,675] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=18,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,680] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=18,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,685] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,26] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,685] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:19:20,685] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:19:20,685] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:19:20,685] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-26 (state.change.logger)
[2016-11-17 18:19:20,682] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,687] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,687] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,18] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 41 (state.change.logger)
[2016-11-17 18:19:20,687] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,691] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:19:20,691] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:19:20,693] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,19] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,693] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:19:20,693] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:19:20,693] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:19:20,693] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-19 (state.change.logger)
[2016-11-17 18:19:20,694] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=18,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,694] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,695] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=24,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,696] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,696] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:19:20,696] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:19:20,697] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,22] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,697] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:19:20,697] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,697] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:19:20,697] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:19:20,697] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-22 (state.change.logger)
[2016-11-17 18:19:20,698] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=24,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,698] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,24] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 44 (state.change.logger)
[2016-11-17 18:19:20,700] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,701] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:19:20,701] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:19:20,701] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,701] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=24,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,703] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=26,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,704] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:19:20,704] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:19:20,706] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,36] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,706] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:19:20,707] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:19:20,707] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:19:20,708] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,708] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-36 (state.change.logger)
[2016-11-17 18:19:20,709] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=26,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,710] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,26] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 47 (state.change.logger)
[2016-11-17 18:19:20,710] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,711] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:19:20,711] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:19:20,712] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=26,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,712] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=19,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,713] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,716] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:19:20,716] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:19:20,717] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,49] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,717] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,717] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:19:20,717] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:19:20,717] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:19:20,717] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-49 (state.change.logger)
[2016-11-17 18:19:20,718] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=19,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,722] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=22,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,725] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,725] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,19] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 50 (state.change.logger)
[2016-11-17 18:19:20,730] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,733] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,734] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:19:20,734] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:19:20,736] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=19,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,737] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:19:20,737] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:19:20,738] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=22,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,740] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=36,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,741] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,22] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 53 (state.change.logger)
[2016-11-17 18:19:20,741] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,741] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:19:20,741] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:19:20,742] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=22,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,742] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,743] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:19:20,743] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:19:20,744] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=36,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,745] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,36] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 56 (state.change.logger)
[2016-11-17 18:19:20,745] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,745] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:19:20,746] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:19:20,746] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=49,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,746] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=36,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,747] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:19:20,747] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:19:20,747] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=49,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,748] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,49] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 59 (state.change.logger)
[2016-11-17 18:19:20,748] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,748] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,749] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:19:20,749] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:19:20,749] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,27] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,749] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:19:20,749] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=49,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,749] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:19:20,749] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:19:20,749] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:19:20,750] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:19:20,750] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=27,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,750] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=27,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,750] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-27 (state.change.logger)
[2016-11-17 18:19:20,750] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,27] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 62 (state.change.logger)
[2016-11-17 18:19:20,750] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,750] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,751] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,751] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:19:20,751] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:19:20,752] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=27,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,752] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:19:20,752] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:19:20,762] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=11,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,765] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,11] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,766] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:19:20,766] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:19:20,766] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:19:20,768] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-11 (state.change.logger)
[2016-11-17 18:19:20,768] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,11] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 65 (state.change.logger)
[2016-11-17 18:19:20,768] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,769] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,769] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=11,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,769] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:19:20,769] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:19:20,769] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,770] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=11,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,770] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:19:20,770] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:19:20,771] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=46,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,773] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,46] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,773] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:19:20,773] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:19:20,773] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:19:20,773] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-46 (state.change.logger)
[2016-11-17 18:19:20,774] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:34,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,46] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 68 (state.change.logger)
[2016-11-17 18:19:20,774] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,774] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=46,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,774] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,775] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,775] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:19:20,775] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:19:20,775] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=46,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,775] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:19:20,775] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:19:20,776] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=31,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,776] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,31] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,776] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:19:20,776] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:19:20,776] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:19:20,776] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-31 (state.change.logger)
[2016-11-17 18:19:20,777] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,31] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 71 (state.change.logger)
[2016-11-17 18:19:20,777] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,777] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,777] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=31,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,777] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:19:20,778] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:19:20,778] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=31,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,778] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,778] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:19:20,778] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:19:20,779] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=2,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,780] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,2] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,780] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:19:20,780] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:19:20,780] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:19:20,780] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-2 (state.change.logger)
[2016-11-17 18:19:20,781] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,2] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 74 (state.change.logger)
[2016-11-17 18:19:20,781] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,781] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,782] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:19:20,782] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:19:20,782] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=2,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,782] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,782] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=2,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,782] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,787] TRACE Controller 2 epoch 60 elected leader 0 for Offline partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,788] TRACE Controller 2 epoch 60 changed partition [othertopic,1] from OnlinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-11-17 18:19:20,788] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,LeaderEpoch:56,ControllerEpoch:60) to broker 2 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,788] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,1,LeaderEpoch:56,ControllerEpoch:60) to broker 1 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,788] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,1,LeaderEpoch:56,ControllerEpoch:60) to broker 0 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,788] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:56,ControllerEpoch:60) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:19:20,788] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:0,ISR:0,1,LeaderEpoch:56,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) correlation id 76 from controller 2 epoch 60 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,789] TRACE Broker 2 handling LeaderAndIsr request correlationId 76 from controller 2 epoch 60 starting the become-follower transition for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,789] TRACE Broker 2 stopped fetchers as part of become-follower request from controller 2 epoch 60 with correlation id 76 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,790] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:56,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:19:20,790] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,1,LeaderEpoch:56,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:19:20,792] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,45] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,792] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:19:20,792] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:19:20,792] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:19:20,793] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-45 (state.change.logger)
[2016-11-17 18:19:20,795] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [othertopic,0] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,795] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:20,795] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:20,795] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:19:20,795] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:19:20,795] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:19:20,796] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,42] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,796] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:19:20,796] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:19:20,797] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:19:20,797] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-42 (state.change.logger)
[2016-11-17 18:19:20,798] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,4] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,798] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:19:20,798] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:19:20,798] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:19:20,798] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-4 (state.change.logger)
[2016-11-17 18:19:20,800] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,41] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,800] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:19:20,800] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:19:20,800] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:19:20,800] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-41 (state.change.logger)
[2016-11-17 18:19:20,801] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,6] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,801] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:19:20,801] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:19:20,801] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:19:20,801] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-6 (state.change.logger)
[2016-11-17 18:19:20,803] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,44] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,803] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:19:20,803] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:19:20,803] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:19:20,803] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-44 (state.change.logger)
[2016-11-17 18:19:20,803] TRACE Broker 2 truncated logs and checkpointed recovery boundaries for partition [othertopic,1] as part of become-follower request with correlation id 76 from controller 2 epoch 60 (state.change.logger)
[2016-11-17 18:19:20,805] TRACE Broker 2 skipped the adding-fetcher step of the become-follower state change with correlation id 76 from controller 2 epoch 60 for partition [othertopic,1] since it is shutting down (state.change.logger)
[2016-11-17 18:19:20,805] TRACE Broker 2 completed LeaderAndIsr request correlationId 76 from controller 2 epoch 60 for the become-follower transition for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:20,805] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,805] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:0,ISR:0,1,LeaderEpoch:56,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:2,0,1) for partition [othertopic,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 77 (state.change.logger)
[2016-11-17 18:19:20,806] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,806] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,37] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,806] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:19:20,806] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:19:20,806] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:19:20,807] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=45,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,807] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,45] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 79 (state.change.logger)
[2016-11-17 18:19:20,807] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,808] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:19:20,808] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:19:20,808] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:19:20,808] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=45,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,808] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:19:20,808] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-37 (state.change.logger)
[2016-11-17 18:19:20,809] TRACE Broker 2 handling stop replica (delete=false) for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:20,809] TRACE Broker 2 finished handling stop replica (delete=false) for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:20,809] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=0,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,809] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,0,LeaderEpoch:50,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:1,2,0) for partition [othertopic,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 82 (state.change.logger)
[2016-11-17 18:19:20,810] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,811] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,811] TRACE Broker 2 handling stop replica (delete=false) for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:20,811] TRACE Broker 2 finished handling stop replica (delete=false) for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:20,811] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=0,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,811] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,812] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:19:20,812] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:19:20,812] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=42,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,812] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,813] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,42] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 85 (state.change.logger)
[2016-11-17 18:19:20,813] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,813] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=0,error_code=13}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,814] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:19:20,814] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:19:20,814] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,814] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=42,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,814] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:19:20,814] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:19:20,814] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,815] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=4,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,815] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,815] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,4] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 88 (state.change.logger)
[2016-11-17 18:19:20,815] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,815] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,816] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:19:20,816] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:19:20,816] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=4,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,816] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,816] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,816] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,817] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:19:20,817] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:19:20,817] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=41,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,817] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,817] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,817] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,41] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 91 (state.change.logger)
[2016-11-17 18:19:20,817] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,818] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:19:20,818] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:19:20,818] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=45,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,818] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=41,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,818] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,819] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:19:20,819] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:19:20,819] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=6,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,819] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=0,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,819] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,6] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 94 (state.change.logger)
[2016-11-17 18:19:20,819] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,820] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,820] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:19:20,820] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:19:20,820] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=6,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,820] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=42,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,821] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:19:20,821] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:19:20,821] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,821] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=44,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,821] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,44] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 97 (state.change.logger)
[2016-11-17 18:19:20,821] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=4,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,821] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,822] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,822] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:19:20,822] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:19:20,822] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=44,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,822] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=41,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,823] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:19:20,823] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:19:20,823] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=37,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,823] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,823] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,37] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 100 (state.change.logger)
[2016-11-17 18:19:20,824] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,824] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=6,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,824] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:19:20,824] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:19:20,824] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,824] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=37,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,825] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=44,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,825] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:19:20,825] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:19:20,825] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=1,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,825] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,826] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=37,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,826] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,827] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,1] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,827] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:19:20,828] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=1,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,828] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:19:20,828] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:19:20,828] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-1 (state.change.logger)
[2016-11-17 18:19:20,828] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,1] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 103 (state.change.logger)
[2016-11-17 18:19:20,829] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,829] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,829] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,830] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:19:20,830] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:19:20,830] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=1,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,831] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:19:20,831] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:19:20,831] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=47,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,832] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,47] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,832] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:19:20,832] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:19:20,832] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:19:20,832] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-47 (state.change.logger)
[2016-11-17 18:19:20,833] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,47] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 106 (state.change.logger)
[2016-11-17 18:19:20,833] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=47,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,833] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,833] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,833] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,833] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:19:20,834] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:19:20,834] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=47,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,834] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:19:20,834] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:19:20,834] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=17,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,835] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,17] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,835] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:19:20,835] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:19:20,835] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:19:20,835] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-17 (state.change.logger)
[2016-11-17 18:19:20,835] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,17] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 109 (state.change.logger)
[2016-11-17 18:19:20,835] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=17,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,836] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,836] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,836] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:19:20,836] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:19:20,836] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,836] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=17,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,837] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:19:20,837] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:19:20,837] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=14,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,838] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,14] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,838] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:19:20,838] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:19:20,838] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:19:20,838] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-14 (state.change.logger)
[2016-11-17 18:19:20,838] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,14] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 112 (state.change.logger)
[2016-11-17 18:19:20,839] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,839] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=14,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,839] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,839] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:19:20,839] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:19:20,839] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,840] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=14,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,840] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:19:20,840] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:19:20,840] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=5,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,840] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,5] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,840] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:19:20,841] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:19:20,841] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:19:20,841] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-5 (state.change.logger)
[2016-11-17 18:19:20,841] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,5] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 115 (state.change.logger)
[2016-11-17 18:19:20,841] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,841] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=5,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,841] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,842] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:19:20,842] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:19:20,842] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,842] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=5,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,842] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:19:20,842] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:19:20,842] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=29,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,843] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,29] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,843] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:19:20,843] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:19:20,843] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:19:20,843] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-29 (state.change.logger)
[2016-11-17 18:19:20,843] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,29] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 118 (state.change.logger)
[2016-11-17 18:19:20,843] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,844] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=29,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,844] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,844] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:19:20,844] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:19:20,844] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,845] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=29,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,845] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:19:20,845] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:19:20,845] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=9,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,846] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,9] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,846] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:19:20,846] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:19:20,846] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:19:20,846] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-9 (state.change.logger)
[2016-11-17 18:19:20,847] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,9] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 121 (state.change.logger)
[2016-11-17 18:19:20,847] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,847] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:19:20,847] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:19:20,847] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=9,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,848] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=9,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,848] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,848] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:19:20,848] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:19:20,848] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,848] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=48,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,849] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,48] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,849] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:19:20,849] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:19:20,850] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:19:20,850] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-48 (state.change.logger)
[2016-11-17 18:19:20,850] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,48] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 124 (state.change.logger)
[2016-11-17 18:19:20,850] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,850] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=48,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,850] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,851] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:19:20,851] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:19:20,851] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,851] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=48,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,851] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:19:20,851] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:19:20,851] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=23,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,852] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,23] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,852] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:19:20,852] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:19:20,852] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:19:20,852] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-23 (state.change.logger)
[2016-11-17 18:19:20,852] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,23] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 127 (state.change.logger)
[2016-11-17 18:19:20,853] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,853] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=23,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,853] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,853] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:19:20,853] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:19:20,853] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,853] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=23,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,854] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:19:20,854] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:19:20,854] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=20,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,855] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,20] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,855] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:19:20,855] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:19:20,855] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:19:20,855] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-20 (state.change.logger)
[2016-11-17 18:19:20,855] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,20] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 130 (state.change.logger)
[2016-11-17 18:19:20,855] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,855] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=20,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,856] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,856] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:19:20,856] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:19:20,856] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,856] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=20,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,856] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:19:20,856] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:19:20,857] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=25,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,857] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,25] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,857] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:19:20,857] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:19:20,857] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:19:20,857] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-25 (state.change.logger)
[2016-11-17 18:19:20,858] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,25] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 133 (state.change.logger)
[2016-11-17 18:19:20,858] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,858] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=25,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,858] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,859] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,859] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:19:20,859] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:19:20,859] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=25,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,859] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:19:20,859] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:19:20,859] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=16,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,860] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,16] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,860] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:19:20,860] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:19:20,861] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,16] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 136 (state.change.logger)
[2016-11-17 18:19:20,861] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:19:20,861] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,861] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-16 (state.change.logger)
[2016-11-17 18:19:20,861] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=16,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,861] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,862] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,862] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:19:20,862] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:19:20,862] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=16,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,862] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:19:20,862] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:19:20,863] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=35,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,864] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,35] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,864] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:19:20,864] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:19:20,864] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:19:20,864] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-35 (state.change.logger)
[2016-11-17 18:19:20,864] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:37,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:2,1) for partition [__consumer_offsets,35] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 139 (state.change.logger)
[2016-11-17 18:19:20,864] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,864] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=35,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,865] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,865] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,865] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:19:20,865] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:19:20,865] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=35,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,866] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:19:20,866] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:19:20,866] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=34,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,867] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,34] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,867] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:19:20,867] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:19:20,867] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:19:20,867] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-34 (state.change.logger)
[2016-11-17 18:19:20,867] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60),ReplicationFactor:2),AllReplicas:1,2) for partition [__consumer_offsets,34] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 142 (state.change.logger)
[2016-11-17 18:19:20,867] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,868] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=34,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,868] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,868] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,868] TRACE Broker 2 handling stop replica (delete=false) for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:19:20,868] TRACE Broker 2 finished handling stop replica (delete=false) for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:19:20,868] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=34,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,869] TRACE Broker 2 handling stop replica (delete=false) for partition [topic2,0] (state.change.logger)
[2016-11-17 18:19:20,869] TRACE Broker 2 finished handling stop replica (delete=false) for partition [topic2,0] (state.change.logger)
[2016-11-17 18:19:20,869] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=0,error_code=0}]} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,887] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [topic2,0] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,887] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 1 for partition [topic2,0] (state.change.logger)
[2016-11-17 18:19:20,887] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 0 for partition [topic2,0] (state.change.logger)
[2016-11-17 18:19:20,887] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 18:19:20,888] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 18:19:20,888] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 18:19:20,888] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60),ReplicationFactor:3),AllReplicas:1,0,2) for partition [topic2,0] in response to UpdateMetadata request sent by controller 2 epoch 60 with correlation id 145 (state.change.logger)
[2016-11-17 18:19:20,888] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(2, 172.16.26.72, 9094) (state.change.logger)
[2016-11-17 18:19:20,889] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=0,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,890] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,890] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=0,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,891] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,891] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,15] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,891] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:19:20,892] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:19:20,892] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:19:20,892] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-15 (state.change.logger)
[2016-11-17 18:19:20,892] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=15,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,892] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,893] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,894] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,10] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,894] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:19:20,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:19:20,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:19:20,894] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-10 (state.change.logger)
[2016-11-17 18:19:20,895] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=10,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,895] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,895] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,896] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,3] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,896] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:19:20,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:19:20,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:19:20,896] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-3 (state.change.logger)
[2016-11-17 18:19:20,897] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=3,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,897] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,897] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,898] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,28] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,899] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:19:20,899] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:19:20,899] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:19:20,899] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-28 (state.change.logger)
[2016-11-17 18:19:20,899] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=28,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,900] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,900] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,901] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,30] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,901] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:19:20,901] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:19:20,901] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:19:20,901] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-30 (state.change.logger)
[2016-11-17 18:19:20,902] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=30,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,902] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,902] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,903] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,43] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,903] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:19:20,904] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:19:20,904] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:19:20,904] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:36,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-43 (state.change.logger)
[2016-11-17 18:19:20,904] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=43,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,905] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,905] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,906] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,0] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,906] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:19:20,906] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:19:20,906] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:19:20,906] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-0 (state.change.logger)
[2016-11-17 18:19:20,907] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=0,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,907] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,907] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,908] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,38] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,908] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:19:20,908] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:19:20,908] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:19:20,908] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-38 (state.change.logger)
[2016-11-17 18:19:20,909] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=38,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,909] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,909] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,910] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,33] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,910] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:19:20,910] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:19:20,911] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:19:20,911] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-33 (state.change.logger)
[2016-11-17 18:19:20,911] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=33,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,911] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,912] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,912] TRACE Controller 2 epoch 60 changed state of replica 2 for partition [__consumer_offsets,8] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,912] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:19:20,912] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 2 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:19:20,913] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 1 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:19:20,913] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:35,ControllerEpoch:60) to broker 0 for partition __consumer_offsets-8 (state.change.logger)
[2016-11-17 18:19:20,913] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=__consumer_offsets,partition=8,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,913] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,914] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,917] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,40] (state.change.logger)
[2016-11-17 18:19:20,919] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,40] due to: No other replicas in ISR 1 for [__consumer_offsets,40] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,919] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,40] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,40] due to: No other replicas in ISR 1 for [__consumer_offsets,40] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,40] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,919] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,39] (state.change.logger)
[2016-11-17 18:19:20,920] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,39] due to: No other replicas in ISR 1 for [__consumer_offsets,39] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,920] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,39] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,39] due to: No other replicas in ISR 1 for [__consumer_offsets,39] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,39] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,924] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [topic2,2] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:20,924] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:10,ControllerEpoch:60) to broker 2 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:20,924] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:10,ControllerEpoch:60) to broker 0 for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:20,924] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:10,ControllerEpoch:60) to broker 2 for partition topic2-2 (state.change.logger)
[2016-11-17 18:19:20,925] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:10,ControllerEpoch:60) to broker 1 for partition topic2-2 (state.change.logger)
[2016-11-17 18:19:20,925] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:10,ControllerEpoch:60) to broker 0 for partition topic2-2 (state.change.logger)
[2016-11-17 18:19:20,925] TRACE Controller 2 epoch 60 started leader election for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,927] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,930] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,932] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,932] TRACE Controller 2 epoch 60 elected leader 0 for Offline partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,933] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:20,933] TRACE Controller 2 epoch 60 changed partition [topic2,1] from OnlinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-11-17 18:19:20,933] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:19,ControllerEpoch:60) to broker 2 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,933] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:19,ControllerEpoch:60) to broker 1 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,933] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:19,ControllerEpoch:60) to broker 0 for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:20,933] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:19,ControllerEpoch:60) to broker 2 for partition topic2-1 (state.change.logger)
[2016-11-17 18:19:20,934] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:19,ControllerEpoch:60) to broker 1 for partition topic2-1 (state.change.logger)
[2016-11-17 18:19:20,934] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:19,ControllerEpoch:60) to broker 0 for partition topic2-1 (state.change.logger)
[2016-11-17 18:19:20,934] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,32] (state.change.logger)
[2016-11-17 18:19:20,935] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=1,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,935] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,32] due to: No other replicas in ISR 1 for [__consumer_offsets,32] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,936] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,32] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,32] due to: No other replicas in ISR 1 for [__consumer_offsets,32] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,32] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,936] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:20,936] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:20,937] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [othertopic,2] due to: No other replicas in ISR 1 for [othertopic,2] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,937] ERROR Controller 2 epoch 60 initiated state change for partition [othertopic,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,2] due to: No other replicas in ISR 1 for [othertopic,2] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [othertopic,2] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,938] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,13] (state.change.logger)
[2016-11-17 18:19:20,940] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,13] due to: No other replicas in ISR 1 for [__consumer_offsets,13] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,940] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,13] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,13] due to: No other replicas in ISR 1 for [__consumer_offsets,13] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,13] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,940] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,21] (state.change.logger)
[2016-11-17 18:19:20,941] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,21] due to: No other replicas in ISR 1 for [__consumer_offsets,21] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,941] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,21] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,21] due to: No other replicas in ISR 1 for [__consumer_offsets,21] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,21] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:20,942] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,12] (state.change.logger)
[2016-11-17 18:19:20,943] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,12] due to: No other replicas in ISR 1 for [__consumer_offsets,12] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,943] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,12] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,12] due to: No other replicas in ISR 1 for [__consumer_offsets,12] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,12] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:20,943] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,7] (state.change.logger)
[2016-11-17 18:19:20,944] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,7] due to: No other replicas in ISR 1 for [__consumer_offsets,7] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,944] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,7] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,7] due to: No other replicas in ISR 1 for [__consumer_offsets,7] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,7] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:20,944] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,18] (state.change.logger)
[2016-11-17 18:19:20,945] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,18] due to: No other replicas in ISR 1 for [__consumer_offsets,18] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,945] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,18] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,18] due to: No other replicas in ISR 1 for [__consumer_offsets,18] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,18] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:20,946] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,24] (state.change.logger)
[2016-11-17 18:19:20,947] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,24] due to: No other replicas in ISR 1 for [__consumer_offsets,24] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,947] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,24] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,24] due to: No other replicas in ISR 1 for [__consumer_offsets,24] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,24] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,948] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,26] (state.change.logger)
[2016-11-17 18:19:20,949] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,26] due to: No other replicas in ISR 1 for [__consumer_offsets,26] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,949] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,26] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,26] due to: No other replicas in ISR 1 for [__consumer_offsets,26] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,26] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,949] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,19] (state.change.logger)
[2016-11-17 18:19:20,950] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,19] due to: No other replicas in ISR 1 for [__consumer_offsets,19] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,950] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,19] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,19] due to: No other replicas in ISR 1 for [__consumer_offsets,19] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,19] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,951] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,22] (state.change.logger)
[2016-11-17 18:19:20,952] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,22] due to: No other replicas in ISR 1 for [__consumer_offsets,22] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,952] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,22] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,22] due to: No other replicas in ISR 1 for [__consumer_offsets,22] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,22] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,952] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,36] (state.change.logger)
[2016-11-17 18:19:20,953] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,36] due to: No other replicas in ISR 1 for [__consumer_offsets,36] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,953] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,36] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,36] due to: No other replicas in ISR 1 for [__consumer_offsets,36] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,36] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,953] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,49] (state.change.logger)
[2016-11-17 18:19:20,955] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,49] due to: No other replicas in ISR 1 for [__consumer_offsets,49] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,955] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,49] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,49] due to: No other replicas in ISR 1 for [__consumer_offsets,49] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,49] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,956] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,27] (state.change.logger)
[2016-11-17 18:19:20,957] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,27] due to: No other replicas in ISR 1 for [__consumer_offsets,27] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,957] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,27] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,27] due to: No other replicas in ISR 1 for [__consumer_offsets,27] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,27] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,958] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,11] (state.change.logger)
[2016-11-17 18:19:20,959] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,11] due to: No other replicas in ISR 1 for [__consumer_offsets,11] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,959] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,11] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,11] due to: No other replicas in ISR 1 for [__consumer_offsets,11] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,11] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,959] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,46] (state.change.logger)
[2016-11-17 18:19:20,960] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,46] due to: No other replicas in ISR 1 for [__consumer_offsets,46] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,960] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,46] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,46] due to: No other replicas in ISR 1 for [__consumer_offsets,46] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,46] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:20,960] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,31] (state.change.logger)
[2016-11-17 18:19:20,962] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,31] due to: No other replicas in ISR 1 for [__consumer_offsets,31] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,962] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,31] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,31] due to: No other replicas in ISR 1 for [__consumer_offsets,31] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,31] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:20,963] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,2] (state.change.logger)
[2016-11-17 18:19:20,998] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,2] due to: No other replicas in ISR 1 for [__consumer_offsets,2] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:20,998] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,2] due to: No other replicas in ISR 1 for [__consumer_offsets,2] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,2] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,001] TRACE Controller 2 epoch 60 changed state of replica 1 for partition [othertopic,1] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:21,001] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:57,ControllerEpoch:60) to broker 2 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:21,001] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:57,ControllerEpoch:60) to broker 0 for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:21,001] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:57,ControllerEpoch:60) to broker 2 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:19:21,002] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:57,ControllerEpoch:60) to broker 1 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:19:21,002] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:57,ControllerEpoch:60) to broker 0 for partition othertopic-1 (state.change.logger)
[2016-11-17 18:19:21,002] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,45] (state.change.logger)
[2016-11-17 18:19:21,004] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,004] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,45] due to: No other replicas in ISR 1 for [__consumer_offsets,45] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,004] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,45] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,45] due to: No other replicas in ISR 1 for [__consumer_offsets,45] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,45] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,004] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,005] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:21,007] TRACE Controller 2 epoch 60 elected leader 0 for Offline partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:21,008] TRACE Controller 2 epoch 60 changed partition [othertopic,0] from OnlinePartition to OnlinePartition with leader 0 (state.change.logger)
[2016-11-17 18:19:21,008] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:51,ControllerEpoch:60) to broker 2 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:21,008] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:51,ControllerEpoch:60) to broker 1 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:21,008] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:0,ISR:0,LeaderEpoch:51,ControllerEpoch:60) to broker 0 for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:21,008] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:51,ControllerEpoch:60) to broker 2 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:19:21,008] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:51,ControllerEpoch:60) to broker 1 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:19:21,008] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:0,ISR:0,LeaderEpoch:51,ControllerEpoch:60) to broker 0 for partition othertopic-0 (state.change.logger)
[2016-11-17 18:19:21,008] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,42] (state.change.logger)
[2016-11-17 18:19:21,010] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,42] due to: No other replicas in ISR 1 for [__consumer_offsets,42] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,010] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,42] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,42] due to: No other replicas in ISR 1 for [__consumer_offsets,42] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,42] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,010] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,4] (state.change.logger)
[2016-11-17 18:19:21,012] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,4] due to: No other replicas in ISR 1 for [__consumer_offsets,4] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,012] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,4] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,4] due to: No other replicas in ISR 1 for [__consumer_offsets,4] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,4] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,012] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,41] (state.change.logger)
[2016-11-17 18:19:21,014] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,41] due to: No other replicas in ISR 1 for [__consumer_offsets,41] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,014] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,41] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,41] due to: No other replicas in ISR 1 for [__consumer_offsets,41] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,41] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,014] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,6] (state.change.logger)
[2016-11-17 18:19:21,015] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,6] due to: No other replicas in ISR 1 for [__consumer_offsets,6] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,015] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,6] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,6] due to: No other replicas in ISR 1 for [__consumer_offsets,6] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,6] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,016] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,44] (state.change.logger)
[2016-11-17 18:19:21,017] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,44] due to: No other replicas in ISR 1 for [__consumer_offsets,44] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,017] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,44] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,44] due to: No other replicas in ISR 1 for [__consumer_offsets,44] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,44] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:21,017] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,37] (state.change.logger)
[2016-11-17 18:19:21,018] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,37] due to: No other replicas in ISR 1 for [__consumer_offsets,37] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,018] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,37] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,37] due to: No other replicas in ISR 1 for [__consumer_offsets,37] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,37] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,018] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,1] (state.change.logger)
[2016-11-17 18:19:21,020] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,1] due to: No other replicas in ISR 1 for [__consumer_offsets,1] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,020] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,1] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,1] due to: No other replicas in ISR 1 for [__consumer_offsets,1] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,1] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,020] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,47] (state.change.logger)
[2016-11-17 18:19:21,021] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,47] due to: No other replicas in ISR 1 for [__consumer_offsets,47] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,021] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,47] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,47] due to: No other replicas in ISR 1 for [__consumer_offsets,47] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,47] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,022] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,17] (state.change.logger)
[2016-11-17 18:19:21,023] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,17] due to: No other replicas in ISR 1 for [__consumer_offsets,17] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,023] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,17] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,17] due to: No other replicas in ISR 1 for [__consumer_offsets,17] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,17] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,023] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,14] (state.change.logger)
[2016-11-17 18:19:21,024] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,14] due to: No other replicas in ISR 1 for [__consumer_offsets,14] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,024] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,14] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,14] due to: No other replicas in ISR 1 for [__consumer_offsets,14] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,14] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,024] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,5] (state.change.logger)
[2016-11-17 18:19:21,026] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,5] due to: No other replicas in ISR 1 for [__consumer_offsets,5] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,026] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,5] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,5] due to: No other replicas in ISR 1 for [__consumer_offsets,5] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,5] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,026] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,29] (state.change.logger)
[2016-11-17 18:19:21,028] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,29] due to: No other replicas in ISR 1 for [__consumer_offsets,29] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,028] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,29] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,29] due to: No other replicas in ISR 1 for [__consumer_offsets,29] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,29] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,028] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,9] (state.change.logger)
[2016-11-17 18:19:21,030] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,9] due to: No other replicas in ISR 1 for [__consumer_offsets,9] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,030] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,9] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,9] due to: No other replicas in ISR 1 for [__consumer_offsets,9] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,9] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,030] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,48] (state.change.logger)
[2016-11-17 18:19:21,031] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,48] due to: No other replicas in ISR 1 for [__consumer_offsets,48] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,031] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,48] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,48] due to: No other replicas in ISR 1 for [__consumer_offsets,48] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,48] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,031] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,23] (state.change.logger)
[2016-11-17 18:19:21,032] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,23] due to: No other replicas in ISR 1 for [__consumer_offsets,23] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,032] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,23] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,23] due to: No other replicas in ISR 1 for [__consumer_offsets,23] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,23] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,033] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,20] (state.change.logger)
[2016-11-17 18:19:21,034] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,20] due to: No other replicas in ISR 1 for [__consumer_offsets,20] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,034] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,20] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,20] due to: No other replicas in ISR 1 for [__consumer_offsets,20] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,20] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:21,034] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,25] (state.change.logger)
[2016-11-17 18:19:21,036] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,25] due to: No other replicas in ISR 1 for [__consumer_offsets,25] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,036] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,25] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,25] due to: No other replicas in ISR 1 for [__consumer_offsets,25] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,25] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:21,037] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,16] (state.change.logger)
[2016-11-17 18:19:21,038] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,16] due to: No other replicas in ISR 1 for [__consumer_offsets,16] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,038] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,16] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,16] due to: No other replicas in ISR 1 for [__consumer_offsets,16] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,16] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:21,038] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,35] (state.change.logger)
[2016-11-17 18:19:21,039] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,35] due to: No other replicas in ISR 1 for [__consumer_offsets,35] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,039] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,35] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,35] due to: No other replicas in ISR 1 for [__consumer_offsets,35] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,35] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:21,040] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,34] (state.change.logger)
[2016-11-17 18:19:21,041] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,34] due to: No other replicas in ISR 1 for [__consumer_offsets,34] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,041] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,34] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,34] due to: No other replicas in ISR 1 for [__consumer_offsets,34] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,34] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,041] TRACE Controller 2 epoch 60 started leader election for partition [topic2,0] (state.change.logger)
[2016-11-17 18:19:21,042] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [topic2,0] due to: No other replicas in ISR 1 for [topic2,0] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,042] ERROR Controller 2 epoch 60 initiated state change for partition [topic2,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,0] due to: No other replicas in ISR 1 for [topic2,0] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [topic2,0] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,043] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,15] (state.change.logger)
[2016-11-17 18:19:21,044] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,15] due to: No other replicas in ISR 1 for [__consumer_offsets,15] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,044] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,15] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,15] due to: No other replicas in ISR 1 for [__consumer_offsets,15] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,15] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,045] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,10] (state.change.logger)
[2016-11-17 18:19:21,046] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,10] due to: No other replicas in ISR 1 for [__consumer_offsets,10] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,046] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,10] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,10] due to: No other replicas in ISR 1 for [__consumer_offsets,10] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,10] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,046] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,3] (state.change.logger)
[2016-11-17 18:19:21,047] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,3] due to: No other replicas in ISR 1 for [__consumer_offsets,3] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,047] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,3] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,3] due to: No other replicas in ISR 1 for [__consumer_offsets,3] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,3] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 21 more
[2016-11-17 18:19:21,047] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,28] (state.change.logger)
[2016-11-17 18:19:21,048] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,28] due to: No other replicas in ISR 1 for [__consumer_offsets,28] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,049] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,28] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,28] due to: No other replicas in ISR 1 for [__consumer_offsets,28] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,28] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,049] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,30] (state.change.logger)
[2016-11-17 18:19:21,050] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,30] due to: No other replicas in ISR 1 for [__consumer_offsets,30] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,050] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,30] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,30] due to: No other replicas in ISR 1 for [__consumer_offsets,30] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,30] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,050] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,43] (state.change.logger)
[2016-11-17 18:19:21,052] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,43] due to: No other replicas in ISR 1 for [__consumer_offsets,43] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,052] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,43] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,43] due to: No other replicas in ISR 1 for [__consumer_offsets,43] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,43] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,052] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,0] (state.change.logger)
[2016-11-17 18:19:21,053] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,0] due to: No other replicas in ISR 1 for [__consumer_offsets,0] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,053] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,0] due to: No other replicas in ISR 1 for [__consumer_offsets,0] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,0] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,054] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,38] (state.change.logger)
[2016-11-17 18:19:21,055] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,38] due to: No other replicas in ISR 1 for [__consumer_offsets,38] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,055] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,38] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,38] due to: No other replicas in ISR 1 for [__consumer_offsets,38] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,38] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,055] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,33] (state.change.logger)
[2016-11-17 18:19:21,056] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,33] due to: No other replicas in ISR 1 for [__consumer_offsets,33] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,056] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,33] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,33] due to: No other replicas in ISR 1 for [__consumer_offsets,33] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,33] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,056] TRACE Controller 2 epoch 60 started leader election for partition [__consumer_offsets,8] (state.change.logger)
[2016-11-17 18:19:21,057] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [__consumer_offsets,8] due to: No other replicas in ISR 1 for [__consumer_offsets,8] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,057] ERROR Controller 2 epoch 60 initiated state change for partition [__consumer_offsets,8] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [__consumer_offsets,8] due to: No other replicas in ISR 1 for [__consumer_offsets,8] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [__consumer_offsets,8] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,058] TRACE Controller 2 epoch 60 started leader election for partition [topic4,0] (state.change.logger)
[2016-11-17 18:19:21,059] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [topic4,0] due to: No other replicas in ISR 1 for [topic4,0] besides shutting down brokers 1,2. (state.change.logger)
[2016-11-17 18:19:21,059] ERROR Controller 2 epoch 60 initiated state change for partition [topic4,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic4,0] due to: No other replicas in ISR 1 for [topic4,0] besides shutting down brokers 1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 1 for [topic4,0] besides shutting down brokers 1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,061] TRACE Controller 2 epoch 60 started leader election for partition [topic2,2] (state.change.logger)
[2016-11-17 18:19:21,062] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [topic2,2] due to: No other replicas in ISR 0 for [topic2,2] besides shutting down brokers 0,1,2. (state.change.logger)
[2016-11-17 18:19:21,062] ERROR Controller 2 epoch 60 initiated state change for partition [topic2,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,2] due to: No other replicas in ISR 0 for [topic2,2] besides shutting down brokers 0,1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 0 for [topic2,2] besides shutting down brokers 0,1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,062] TRACE Controller 2 epoch 60 started leader election for partition [topic2,1] (state.change.logger)
[2016-11-17 18:19:21,063] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [topic2,1] due to: No other replicas in ISR 0 for [topic2,1] besides shutting down brokers 0,1,2. (state.change.logger)
[2016-11-17 18:19:21,063] ERROR Controller 2 epoch 60 initiated state change for partition [topic2,1] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [topic2,1] due to: No other replicas in ISR 0 for [topic2,1] besides shutting down brokers 0,1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 0 for [topic2,1] besides shutting down brokers 0,1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,065] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [othertopic,2] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:21,065] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 2 for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:21,065] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition [othertopic,2] (state.change.logger)
[2016-11-17 18:19:21,065] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 2 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:19:21,065] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 1 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:19:21,065] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:50,ControllerEpoch:60) to broker 0 for partition othertopic-2 (state.change.logger)
[2016-11-17 18:19:21,065] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,1] (state.change.logger)
[2016-11-17 18:19:21,066] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [othertopic,1] due to: No other replicas in ISR 0 for [othertopic,1] besides shutting down brokers 0,1,2. (state.change.logger)
[2016-11-17 18:19:21,066] ERROR Controller 2 epoch 60 initiated state change for partition [othertopic,1] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,1] due to: No other replicas in ISR 0 for [othertopic,1] besides shutting down brokers 0,1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 0 for [othertopic,1] besides shutting down brokers 0,1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,067] TRACE Controller 2 epoch 60 started leader election for partition [othertopic,0] (state.change.logger)
[2016-11-17 18:19:21,068] ERROR Controller 2 epoch 60 encountered error while electing leader for partition [othertopic,0] due to: No other replicas in ISR 0 for [othertopic,0] besides shutting down brokers 0,1,2. (state.change.logger)
[2016-11-17 18:19:21,068] ERROR Controller 2 epoch 60 initiated state change for partition [othertopic,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [othertopic,0] due to: No other replicas in ISR 0 for [othertopic,0] besides shutting down brokers 0,1,2.
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:265)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(KafkaController.scala:260)
	at scala.Option.foreach(Option.scala:257)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply$mcV$sp(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3$$anonfun$apply$1.apply(KafkaController.scala:260)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:259)
	at kafka.controller.KafkaController$$anonfun$shutdownBroker$3.apply(KafkaController.scala:256)
	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:322)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:978)
	at kafka.controller.KafkaController.shutdownBroker(KafkaController.scala:256)
	at kafka.server.KafkaApis.handleControlledShutdownRequest(KafkaApis.scala:174)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:75)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:60)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: No other replicas in ISR 0 for [othertopic,0] besides shutting down brokers 0,1,2
	at kafka.controller.ControlledShutdownLeaderSelector.selectLeader(PartitionLeaderSelector.scala:196)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 22 more
[2016-11-17 18:19:21,070] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [topic2,0] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:21,070] TRACE Controller 2 epoch 60 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 2 for partition [topic2,0] (state.change.logger)
[2016-11-17 18:19:21,070] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 1 for partition [topic2,0] (state.change.logger)
[2016-11-17 18:19:21,070] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 2 for partition topic2-0 (state.change.logger)
[2016-11-17 18:19:21,070] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 1 for partition topic2-0 (state.change.logger)
[2016-11-17 18:19:21,070] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:16,ControllerEpoch:60) to broker 0 for partition topic2-0 (state.change.logger)
[2016-11-17 18:19:21,072] TRACE Controller 2 epoch 60 changed state of replica 0 for partition [topic4,0] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-11-17 18:19:21,072] TRACE Controller 2 epoch 60 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:60) to broker 1 for partition [topic4,0] (state.change.logger)
[2016-11-17 18:19:21,072] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:60) to broker 2 for partition topic4-0 (state.change.logger)
[2016-11-17 18:19:21,072] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:60) to broker 1 for partition topic4-0 (state.change.logger)
[2016-11-17 18:19:21,072] TRACE Controller 2 epoch 60 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:4,ControllerEpoch:60) to broker 0 for partition topic4-0 (state.change.logger)
[2016-11-17 18:19:21,074] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=2,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,077] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=1,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,077] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,078] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,078] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,079] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=1,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,081] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=0,error_code=0}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,082] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,082] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=2,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,083] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,083] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=0,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,084] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,084] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic4,partition=0,error_code=13}]} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,084] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(1, 172.16.26.72, 9093) (state.change.logger)
[2016-11-17 18:19:21,310] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=0,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,311] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,320] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=2,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,320] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,321] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=othertopic,partition=2,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,322] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=0,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,322] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,323] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic2,partition=0,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,323] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic4,partition=0,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,323] TRACE Controller 2 epoch 60 received response {error_code=0} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,324] TRACE Controller 2 epoch 60 received response {error_code=0,partitions=[{topic=topic4,partition=0,error_code=0}]} for a request sent to broker Node(0, 172.16.26.72, 9092) (state.change.logger)
[2016-11-17 18:19:21,348] TRACE Broker 2 handling stop replica (delete=false) for partition [topic2,0] (state.change.logger)
[2016-11-17 18:19:21,348] TRACE Broker 2 finished handling stop replica (delete=false) for partition [topic2,0] (state.change.logger)
